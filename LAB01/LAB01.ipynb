{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MastafaF/Lab1_EPITA/blob/main/Lab1_EPITA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMwkByBnaE49"
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"data:image/jpeg;base64,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\" alt=\"EPITA Lab 1\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKtcL0CYn2n_"
   },
   "source": [
    "# Part 1. Keywords Extraction (14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXcmrzodG1pt"
   },
   "source": [
    "## What is Keyword Extraction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZWKLXCYG9NJ"
   },
   "source": [
    "Keyword extraction is defined as the task that automatically identifies a set of the terms that best describe the subject of document. This is an important method in information retrieval (IR) systems: keywords simplify and speed up the search. Keyword extraction can be used to reduce the dimensionality of text for further text analysis (text classification ot topic modeling). S.Art et al., for example, extracted keywords to measure patent similarity. Using keyword extraction, you can automatically index data, summarize a text, or generate tag clouds with the most representative keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O3FI910HETW"
   },
   "source": [
    "## How to extract the keywords?\n",
    "All keyword extraction algorithms include the following steps:\n",
    "\n",
    "* Candidate generation. Detection of possible candidate keywords from the text.\n",
    "* Property calculation. Computation of properties and statistics required for ranking.\n",
    "* Ranking. Computation of a score for each candidate keyword and sorting in descending order of all candidates. The top n candidates are finally selected as the n keywords representing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wD64EYyAHE5k"
   },
   "outputs": [],
   "source": [
    "# all the imports \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr3WHRR0C9Il"
   },
   "source": [
    "## Goal.\n",
    "\n",
    "In the following, given a paper, we will extract the keywords associated to this paper. Each individual can have their own qualitative assessment of what is \"key\" word. However, we will try as much as possible to objectify the approach and quantify to what extent a keyword is indeed key to the paper in question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoUQe5Df4Bpr"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xT3cUUST9QX6"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! git clone https://github.com/MastafaF/ExtractKeywords.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duJTpCLQ9XJ5",
    "outputId": "ad8f1b4b-d581-4c7b-9f7e-627743427381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git', 'README.md', 'LICENSE', 'data.tar.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.listdir(\"./ExtractKeywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfVjwTfE9dyP",
    "outputId": "e856be29-c340-4024-c740-24b438aa2f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/papers.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract data file \n",
    "\n",
    "! cd ExtractKeywords && tar -zxvf data.tar.gz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CdRVtKw44C9p",
    "outputId": "9e0c179a-637b-48bb-9d9f-792383f0291c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ac22bdea-2a37-4f3a-ba84-6f1650b185c7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac22bdea-2a37-4f3a-ba84-6f1650b185c7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ac22bdea-2a37-4f3a-ba84-6f1650b185c7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ac22bdea-2a37-4f3a-ba84-6f1650b185c7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('./ExtractKeywords/data/papers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2IElpuJ76o0"
   },
   "source": [
    "## Preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRAj0JXjAWBo",
    "outputId": "e84f3333-1c5d-452d-cd53-9d986de451b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the Lemmatizer \n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHC9ShM-IX7E"
   },
   "source": [
    "### Question 1.1: Preprocessing data in a meaningful way [code] (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWpI1OJk78Gc",
    "outputId": "6fa27ed0-584d-42a1-9c78-b76fd1f9dbee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "# Update stop words accordingly\n",
    "#my_stop_words = STOPWORDS.union(set(['mystopword1', 'mystopword2']))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "##Creating a list of custom stopwords\n",
    "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\", \n",
    "             \"show\", \"result\", \"large\", \n",
    "             \"also\", \"one\", \"two\", \"three\", \n",
    "             \"four\", \"five\", \"seven\",\"eight\",\"nine\"]\n",
    "\n",
    "stop_words = STOPWORDS.union(set(new_words))\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "def pre_process(text):\n",
    "  # ------------------\n",
    "  # Write your implementation here.\n",
    "  wnl = WordNetLemmatizer()\n",
    "\n",
    "  text = text.lower()\n",
    "  text = re.sub('[^a-zA-Z]+', ' ', text)\n",
    "  word_list = text.split()\n",
    "  word_list = [word for word in word_list if word not in stop_words and len(word) > 2]\n",
    "  word_list = [wnl.lemmatize(word) for word in word_list]\n",
    "  return ' '.join(word_list)\n",
    "  # ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZFsz9JX_9I0",
    "outputId": "34327a2c-f92e-422c-e6ab-b59b32bb1f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 213 ms, total: 1min 3s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['preproc_text'] = df['paper_text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "_3ADgBBsAHhg",
    "outputId": "87ab3798-f5ff-430d-8021-92a3ff491253"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preproc_text</th>\n",
       "      <td>self organization associative database application hisashi suzuki suguru arimoto osaka university toyonaka osaka japan abstract efficient method self organizing associative database proposed application robot eyesight system proposed database associate input output half discussion algorithm self organization proposed aspect hardware produce new style neural network half applicability handwritten letter recognition autonomous mobile robot demonstrated introduction let mapping given finite infinite set finite infinite set learning machine observes set pair sampled randomly mean cartesian product computes estimate small estimation error measure usually faster decrease estimation error increase number sample better learning machine expression performance incomplete lack consideration candidate assumed preliminarily good learning machine clarify conception let discus type learning machine let advance understanding self organization associative database parameter type ordinary type learning machine assumes equation relating parameter indefinite structure equivalent define implicitly set candidate subset mapping computes value parameter based observed sample type parameter type learning machine defined approach number sample increase alternative case estimation error remains eternally problem designing learning machine return proper structure sense hand assumed structure demanded compact possible achieve fast learning word number parameter small parameter uniquely determined observed sample demand proper contradicts compact consequently parameter type better compactness assumed structure proper better learning machine elementary conception design learning machine universality ordinary neural network suppose sufficient knowledge given unknown case comparatively easy proper compact structure alternative case difficult possible solution compactness assume almighty structure cover combination orthogonal base infinite dimension structure neural network approximation obtained truncating finitely dimension implementation american institute physic main topic designing neural network establish desirable structure work includes developing practical procedure compute value coefficient observed sample discussion flourishing efficient method proposed recently hardware unit computing coefficient parallel speed sold anza mark iii odyssey neural network exists danger error remaining eternally estimating precisely speaking suppose combination base finite number define structure essentially word suppose located near case estimation error negligible distant estimation error negligible research report following situation appears complex estimation error converges value number sample increase decrease hardly dimension heighten property considerable defect neural network recursi type recursive type founded methodology learning follows initial stage set instead notation candidate equal set mapping observing reduced observing second reduced candidate set gradually small observation sample proceeds observing sample write likelihood estimation selected contrarily parameter type recursive type guarantee surely approach number sample increase recursive type observes rewrite value correlated type architecture composed rule rewriting free memory space architecture form naturally kind database build management system data self organizing way database differs ordinary one following sense record sample observed computes estimation database associative database subject constructing associative database establish rule rewri ting purpose adap measure called dissimilari dissimilari mean mapping real necessarily defined single formula definable example collection rule written form dissimilarity defines structure locally knowledge imperfect flect heuristic way contrarily neural network possible accelerate speed learning establishing especially easily simple process analogically information like human application paper recursive type show strongly effectiveness denote sequence observed sample simplest construction associative database observing sample follows algorithm initial stage let set let equal min furthermore add produce version improved economize memory follows algorithm initial stage let composed arbitrary element let lex equal min furthermore let add produce construction approach increase computation time grows proportionally size second subject constructing associative database addressing rule employ economize computation time subsequent chapter construction associative database purpose proposed manages data form binary tree self organization associative database given sequence algorithm constructing associative database follows algorithm step initialization let root root variable assigned respective node memorize data furthermore let step increase reset pointer root repeat following arrives terminal node leaf notation nand let mean descendant node let step display yin related information yin step establish new descendant node secondly let yin yin yin finally step loop step stopped time continued suppose gate element artificial synapsis play role branching prepared obtain new style neural network gate element randomly connected algorithm letter recognition recen tly vertical slitting method recognizing typographic english letter elastic matching method recognizing hand written discrete english letter global training fuzzy logic search method recognizing chinese character written square style published self organization associative database realizes recognition handwritten continuous english letter nov source document loo windowing number sample nualber sampl experiment scanner take document letter recognizer us parallelogram window cover maximal letter process sequence letter shifting window recognizer scan word slant direction place window left vicinity black point detected window catch letter succeeding letter recognition head letter performed end position boundary line letter known starting scanning boundary repeating operation recognizer accomplishes recursively task major problem come identifying head letter window considering define following regard window image define accordingly denote black point left area boundary window project window measure euclidean distance black point closest let summation black point divided number regard couple reading position boundary define accordingly operator teach recognizer interaction relation window reading boundary algorithm precisely recalled reading incorrect operator teach correct reading console boundary position incorrect teach correct position mouse show partially document experiment show change number node recognition rate defined relative frequency correct answer past trial speciiications window height dot width dot slant angular deg example level tree distributed time recognition rate converged experimentally recognition rate converges case rare case attain distinguishable excessive lluctuation writing consistency relation assured like number node increase endlessly clever stop learning recognition rate attains upper limit improve recognition rate consider spelling word future subject obstacle avoiding movement system camera type autonomous mobile robot reported flourishingly author belongs category mathematical methodology solve usually problem obstacle avoiding movement cost minimization problem cost criterion established artificially contrarily self organization associative database reproduces faithfully cost criterion operator motion robot learning natural length width height robot weight visual angle camera deg robot following factor motion turn deg advance control speed experiment passageway wid inside building author laboratory exist experimental intention arrange box smoking stand gas cylinder stool handcart passage way random let robot camera recall similar trace route preliminarily recorded purpose define following let camera face deg downward process low pas filter scanning vertically filtered search point luminance change excessively bstitu point white point black obstacle exists robot white area show free area robot regard binary dot image processed define accordingly let number black point exclusive regard image obtained drawing route image define accordingly robot superimposes current camera route recalled inquires operator instruction operator judge subjectively suggested route appropriate negative answer draw desirable route mouse teach new robot opera tion defines implicitly sequence reflecting cost criterion operator iibube roan stationary uni configuration autonomous mobile robot north rmbi unit robot roan experimental environment wall camera preprocessing preprocessing course suggest ion search processing obstacle avoiding movement processing position identification define satisfaction rate relative frequency acceptable suggestion route past trial typical experiment change satisfaction rate showed similar tendency attains time notice rest mean directly percentage collision practice prevent collision adopting supplementary measure time number node level tree distributed proposed method reflects delicately character operator example robot trained operator move slowly space obstacle trained operator brush quickly obstacle fact give hint method printing character machine position identification robot identify position recalling similar landscape position data camera purpose principle suffices regard camera image position data respectively memory capacity finite actual compu ters compress camera image slight loss information compression admittable long precision position identification acceptable area major problem come suitable compression method experimental environment jut passageway interval section adjacent jut door robot identifies roughly surrounding landscape section place us temporarily triangular surveying technique exact measure necessary realize task define following turn camera panorama deg scanning horizontally center line substitute point luminance excessively change black point white regard binary dot line image processed define accordingly project black point measure euclidean distance black point closest let summation similarly calculate exchanging role denoting number respectively nand define regard positive integer labeled section define accordingly learning mode robot check exactly position counter reset periodically operator robot run arbitrarily passageway area learns relation landscape position data position identification area achieved crossing plural database task automatic excepting periodic reset counter kind learning teacher define identification rate relative frequency correct recall position data past trial typical example converged time time number level level oftree distributed identification failure rejected considering trajectory pro blem arises practical use order improve identification rate compression ratio camera image loosened possibility depends improvement hardware future show example actual motion robot based database obstacle avoiding movement position identification example corresponds case moving time interval frame sec actual motion robot conclusion method self organizing associative database proposed application robot eyesight system machine decomposes global structure unknown set local structure known learns universally input output response framework problem implies wide application area example shown paper defect algorithm self organization tree balanced subclass structure subject imposed widen class probable solution abolish addressing rule depending directly value instead establish rule depending distribution function value investigation reference hopfield tank computing neural circuit model science rumelhart learning representation propagating error nature hull hypothesis generation computational model visual word recognition ieee expert fall kurtzberg feature analysis symbol recognition elastic matching ibm re develop wang suen tree classifier heuristic search global training ieee trans pattern anal mach intell pami brook self calibration motion stereo vision mobile robot int symp robotics research goto stentz cmu mobile robot navigation ieee int conf robotics automation madarasz design autonomous vehicle disabled ieee jour robotics automation triendl kriegman stereo vision navigation building ieee int conf robotics automation turk video road following autonomous land vehicle ieee int conf robotics automation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing data \n",
    "HTML(pd.DataFrame(df.loc[0, [\"preproc_text\"]]).to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLS9mbe8B4UY"
   },
   "source": [
    "## 0. Raw counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WY9c6iwI0Lv"
   },
   "source": [
    "### Question 1.2: Build a top N words based on occurence [code] (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izLhCAH5B-jy",
    "outputId": "1199604c-16d5-42c1-b89f-cd1d99764e97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Idea: \n",
    "\n",
    "0. Split with spacy OR nltk \n",
    "\n",
    "1. Counter \n",
    "\n",
    "2. Surface top 10 \n",
    "\n",
    "\"\"\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def get_counter(txt_preproc, N=10): \n",
    "\n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    token_list = word_tokenize(txt_preproc)\n",
    "    counter = {}\n",
    "    for token in token_list:\n",
    "        counter[token] = counter.get(token, 0) + 1\n",
    "    \n",
    "    sorted_tokens = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_tokens[:N]\n",
    "\n",
    "    # ------------------\n",
    "\n",
    "df[\"Top N\"] = df[\"preproc_text\"].apply(get_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJNxYJNP-wSy",
    "outputId": "2f399586-a440-4a3d-d0e3-d4e35786f441"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('input', 58),\n",
       " ('weak', 42),\n",
       " ('synaptic', 36),\n",
       " ('associative', 35),\n",
       " ('ltp', 30),\n",
       " ('strong', 26),\n",
       " ('phase', 26),\n",
       " ('long', 24),\n",
       " ('stimulus', 23),\n",
       " ('hippocampus', 22)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2, \"Top N\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK7YbNCyJaqk"
   },
   "source": [
    "### Question 1.3: What are some of the limits of raw counts? How could we improve the approach through preprocessing? [written] (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eewWd_TjJlt-"
   },
   "source": [
    "One limit is that the most frequent word in a document might actually be common words which are very frequent in all documents, in the same manner as stop words. One could improve this approach by adding these words in our stop words list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wao4NivXGPIM"
   },
   "source": [
    "## 1. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TRcD4MeHFnt"
   },
   "source": [
    "### Introduction.\n",
    "\n",
    "TF-IDF stands for Text Frequency Inverse Document Frequency. The importance of each word increases proportionally to the number of times a word appears in the document (Text Frequency - TF) but is offset by the frequency of the word in the corpus (Inverse Document Frequency - IDF). Using the tf-idf weighting scheme, the keywords are the words with the higherst TF-IDF score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOZe8obbHm-Q"
   },
   "source": [
    "### CountVectorizer to create a vocabulary and generate word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pd54cOkGV_p",
    "outputId": "af4ed49d-4808-4ad1-9f83-cdaae3be875f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 3.45 s, total: 1min 53s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#create a vocabulary of words, \n",
    "cv=CountVectorizer(max_df=0.95,         # ignore words that appear in 95% of documents\n",
    "                   max_features=10000,  # the size of the vocabulary\n",
    "                   ngram_range=(1,3)    # vocabulary contains single words, bigrams, trigrams\n",
    "                  )\n",
    "\n",
    "\n",
    "word_count_vector=cv.fit_transform(df[\"preproc_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fngZVCVGcG_",
    "outputId": "cc8329bc-2241-4de9-d458-53032aaeb0e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7241x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5593481 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxV_evcXHuKp"
   },
   "source": [
    "### TfidfTransformer to Compute Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCfwFzHCHzOY",
    "outputId": "248e2610-3bff-473f-aa55-536e193d53df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.9 ms, sys: 2.98 ms, total: 27.9 ms\n",
      "Wall time: 33.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd9hXGWJHzLy",
    "outputId": "a120ea1c-438f-4a52-b50c-1ee714e9be48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1wbWizrJ5CE"
   },
   "source": [
    "### Question 1.4: How can you find an optimal max_df? Why are we using a sparse matrix instead of a regular matrix? [written] (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EekhsGbKYoyv"
   },
   "source": [
    "We can test multiple values of max_df and pick the one with the best performance. Performance can be evaluated depending on our objective, for example it can be manual, or evaluated on a semantic search task.  \n",
    "We are using sparse matrix because most of the rows will be equal to 0 as most of the words in our vocabulary will not appear in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2_9miFxKaU1",
    "outputId": "6c282124-a9a5-4813-fdcb-d3f54c79f5da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\" change number node recognition rate defined relative frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "K2Vdn9NTMIxI",
    "outputId": "f722d4e9-82e0-407b-9eb3-6c793961fd30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7feda52251f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing data \n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "plt.spy(csr_matrix(cv.transform([\"change number node recognition rate defined relative frequency\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRI_AZtROxP0",
    "outputId": "3c6f6aee-7ceb-47f8-cedc-2a84e1595ba1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7343, 0.6387503245819366),\n",
       " (6083, 0.48227455357029786),\n",
       " (3278, 0.2826615514521735),\n",
       " (5943, 0.2670244641045569),\n",
       " (7333, 0.2285836952179592),\n",
       " (7473, 0.22171918342682348),\n",
       " (1176, 0.192004012179769),\n",
       " (7254, 0.17648064980292605),\n",
       " (2061, 0.15316537964943927),\n",
       " (6060, 0.12381100409601017)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([\"change number node recognition rate defined relative frequency\"]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0IrBlZtGu-k",
    "outputId": "e9239248-1fd6-40ad-bf85-8a9f8941cfc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxhq2LiEOxD3",
    "outputId": "5237d19a-3e68-44db-b48c-409c50a0f738"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_matrix = tf_idf_vector.tocoo()\n",
    "# list(zip(coo_matrix.col, coo_matrix.data))\n",
    "coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4EwdqH_Gm0C",
    "outputId": "964e3b74-a225-477c-a99c-e3fbc140c41f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# get feature names\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "def get_keywords(txt, top_N=10):\n",
    "\n",
    "  # ------------------\n",
    "  # Write your implementation here.\n",
    "  tf_idf_vector=tfidf_transformer.transform(cv.transform([txt]))\n",
    "  \n",
    "  sorted_items=sort_coo(tf_idf_vector.tocoo())[:top_N]\n",
    "  \n",
    "  sorted_keyword_score = []\n",
    "  \n",
    "  for el in sorted_items :\n",
    "    sorted_keyword_score.append((feature_names[el[0]], round(el[1], 3)))\n",
    "  \n",
    "  # ------------------\n",
    "  \n",
    "  return sorted_keyword_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahvTo9gjSWCW",
    "outputId": "4b9dd550-fae2-4ae3-9662-593b78ff2821"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recognition rate', 0.639),\n",
       " ('number node', 0.482),\n",
       " ('frequency', 0.283),\n",
       " ('node', 0.267),\n",
       " ('recognition', 0.229),\n",
       " ('relative', 0.222),\n",
       " ('change', 0.192),\n",
       " ('rate', 0.176),\n",
       " ('defined', 0.153),\n",
       " ('number', 0.124)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keywords(txt=\"change number node recognition rate defined relative frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9hzsg0CUQZ_"
   },
   "source": [
    "### Compare Raw Counts to Tf-IDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ot6GLVIiUPqj"
   },
   "outputs": [],
   "source": [
    "df[\"Top_N_TF-IDF\"] = df[\"preproc_text\"].apply(get_keywords, top_N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "g4sydV20UjvA",
    "outputId": "4695d8b2-4639-4c49-be21-2a23f3b4eeb6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-26bdad2b-400a-4be2-a3f1-37251422f1f7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>preproc_text</th>\n",
       "      <th>Top N</th>\n",
       "      <th>Top_N_TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1466</td>\n",
       "      <td>1997</td>\n",
       "      <td>Independent Component Analysis for Identificat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1466-independent-component-analysis-for-identi...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Independent Component Analysis for\\nidentifica...</td>\n",
       "      <td>independent component analysis identification ...</td>\n",
       "      <td>[(artifact, 38), (independent, 32), (signal, 3...</td>\n",
       "      <td>[(artifact, 0.563), (meg, 0.382), (independent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26bdad2b-400a-4be2-a3f1-37251422f1f7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-26bdad2b-400a-4be2-a3f1-37251422f1f7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-26bdad2b-400a-4be2-a3f1-37251422f1f7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       id  year                                              title event_type  \\\n",
       "509  1466  1997  Independent Component Analysis for Identificat...        NaN   \n",
       "\n",
       "                                              pdf_name          abstract  \\\n",
       "509  1466-independent-component-analysis-for-identi...  Abstract Missing   \n",
       "\n",
       "                                            paper_text  \\\n",
       "509  Independent Component Analysis for\\nidentifica...   \n",
       "\n",
       "                                          preproc_text  \\\n",
       "509  independent component analysis identification ...   \n",
       "\n",
       "                                                 Top N  \\\n",
       "509  [(artifact, 38), (independent, 32), (signal, 3...   \n",
       "\n",
       "                                          Top_N_TF-IDF  \n",
       "509  [(artifact, 0.563), (meg, 0.382), (independent...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkDLV8yILNNS"
   },
   "source": [
    "### Question 1.5: Find an example where there is a noticeable difference between tf-idf and raw counts? Justify which method you would choose yourself (there is no bad and good answer here) [written] (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wo412lRLVi02",
    "outputId": "b5207b3c-ff42-4514-c8b4-26e0e0d0c6dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition\n",
      "Top-3 using raw counts : [('information', 79), ('feature', 66), ('test', 59)]\n",
      "Top-3 using Tf-idf : [('diagnosis', 0.43), ('induction', 0.353), ('acquisition', 0.283)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Title : \" + df[df.id == 3653][\"title\"].item())\n",
    "print(\"Top-3 using raw counts : \" + str(df[df.id == 3653][\"Top N\"].item()[:3]))\n",
    "print(\"Top-3 using Tf-idf : \" + str(df[df.id == 3653][\"Top_N_TF-IDF\"].item()[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7_1jb22UWv4"
   },
   "source": [
    "On this example, the top-3 words are \"information, feature, test\" using raw counts and \"diagnosis, induction, acquisition\" using tf-idf. In this case the top-3 words using raw counts seem to be more generic than the top-3 words using tf-idf (these appear in the title of the document). Thus, we would use the tf-idf as it seems more likely to output the correct document in a context of semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mes_RnLNVXBX"
   },
   "source": [
    "## 2. KeyBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7iWThDYXlJY"
   },
   "source": [
    "## 2.0. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "g0Ji149nXmUU"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "k-kXWUGKXqIB"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from keybert import KeyBERT\n",
    "\n",
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal). \n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the \n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires \n",
    "         the learning algorithm to generalize from the training data to unseen situations in a \n",
    "         'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNrYae2jYDqU",
    "outputId": "18595689-7d43-45ca-ca58-2083d74c41aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supervised', 0.6676),\n",
       " ('labeled', 0.4896),\n",
       " ('learning', 0.4813),\n",
       " ('training', 0.4134),\n",
       " ('labels', 0.3947)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJs_f30AYmKN"
   },
   "source": [
    "### Question 2.0. Apply KeyBERT to the a sample of the dataset [code] (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "7GisGAL0pIDy",
    "outputId": "ee346d69-c6bb-4071-af3f-f4821a9695f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f293fa45-d326-4d47-a31a-bcec7326aad7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>preproc_text</th>\n",
       "      <th>Top N</th>\n",
       "      <th>Top_N_TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>694</td>\n",
       "      <td>1992</td>\n",
       "      <td>Kohonen Feature Maps and Growing Cell Structur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>694-kohonen-feature-maps-and-growing-cell-stru...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Kohonen Feature Maps and Growing\\nCell Structu...</td>\n",
       "      <td>kohonen feature map growing cell structure per...</td>\n",
       "      <td>[(network, 41), (distribution, 41), (neuron, 3...</td>\n",
       "      <td>[(kohonen, 0.439), (neuron, 0.318), (growing, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f293fa45-d326-4d47-a31a-bcec7326aad7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f293fa45-d326-4d47-a31a-bcec7326aad7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f293fa45-d326-4d47-a31a-bcec7326aad7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       id  year                                              title event_type  \\\n",
       "6566  694  1992  Kohonen Feature Maps and Growing Cell Structur...        NaN   \n",
       "\n",
       "                                               pdf_name          abstract  \\\n",
       "6566  694-kohonen-feature-maps-and-growing-cell-stru...  Abstract Missing   \n",
       "\n",
       "                                             paper_text  \\\n",
       "6566  Kohonen Feature Maps and Growing\\nCell Structu...   \n",
       "\n",
       "                                           preproc_text  \\\n",
       "6566  kohonen feature map growing cell structure per...   \n",
       "\n",
       "                                                  Top N  \\\n",
       "6566  [(network, 41), (distribution, 41), (neuron, 3...   \n",
       "\n",
       "                                           Top_N_TF-IDF  \n",
       "6566  [(kohonen, 0.439), (neuron, 0.318), (growing, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df.sample(100)\n",
    "df_.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CN3Dlu11YwLE",
    "outputId": "6240896e-f4a6-4565-ac99-e9f6ba6b12c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 s, sys: 7.18 s, total: 34.3 s\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "# ------------------\n",
    "# Write your implementation here.\n",
    "df_[\"Top_N_KeyBERT_1\"] = df_[\"preproc_text\"].apply(kw_model.extract_keywords, top_n=10)\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXwvxJgRuupD",
    "outputId": "36aa1eab-7fd0-4678-e244-89cb2d024cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Gaussian Process Bandit Optimization via Determinantal Point Processes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dpp', 92),\n",
       " ('ucb', 60),\n",
       " ('function', 56),\n",
       " ('algorithm', 55),\n",
       " ('regret', 46),\n",
       " ('bound', 44),\n",
       " ('est', 44),\n",
       " ('batch', 43),\n",
       " ('method', 39),\n",
       " ('point', 37)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compare the same paper example across the 3 methods \n",
    "\n",
    "idx_focus = 6027 \n",
    "\n",
    "print(df.loc[idx_focus, \"title\"])\n",
    "\n",
    "df.loc[idx_focus, \"Top N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyrW4RYgwyfU",
    "outputId": "3433315a-5302-41e6-bb3f-98a6c0660b7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dpp', 0.737),\n",
       " ('ucb', 0.354),\n",
       " ('est', 0.267),\n",
       " ('regret', 0.208),\n",
       " ('batch', 0.151),\n",
       " ('regret bound', 0.128),\n",
       " ('bound', 0.09),\n",
       " ('kernel', 0.083),\n",
       " ('bayesian optimization', 0.082),\n",
       " ('algorithm', 0.076)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[idx_focus, \"Top_N_TF-IDF\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWh7EP7CwzFe",
    "outputId": "2ddc833d-2d5d-478e-bc16-8bdeee4b4db1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('optimizer', 0.4337),\n",
       " ('bandit', 0.4139),\n",
       " ('optimizing', 0.4049),\n",
       " ('optimisation', 0.3937),\n",
       " ('batch', 0.3457),\n",
       " ('optimization', 0.3333),\n",
       " ('hyperparameter', 0.3163),\n",
       " ('strategy', 0.2958),\n",
       " ('search', 0.2882),\n",
       " ('algorithmica', 0.2873)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.loc[idx_focus, \"Top_N_KeyBERT_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9GQQGMTZgrR"
   },
   "source": [
    "### Question 2.2. Comparison of multilple techniques [written] (4 points)\n",
    "\n",
    "1. Draw a table of the solution, the quality score that you defined and the time taken to find keywords across a sample of 1000 of the original dataset.\n",
    "2. Can you think of tweaks to reduce time to compute? If yes, add an additional column to the above table with your proposed tweaks.\n",
    "3. Based on the above table and  lecture 1, what do you think is the most appropriate solution for keywords extraction? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yLNjUqJEm89"
   },
   "outputs": [],
   "source": [
    "def get_keywords_quality(df, topN_col) :\n",
    "  df['preproc_title'] = df['title'].apply(pre_process)\n",
    "  \n",
    "  keywords_quality = 0\n",
    "  for _, doc in df.iterrows():\n",
    "    for i in range(10) :\n",
    "      if i < len(doc[topN_col]) and doc[topN_col][i][0] in doc[\"preproc_title\"] :\n",
    "        keywords_quality += 10 - i\n",
    "\n",
    "  return keywords_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY9yCZun8LWT"
   },
   "outputs": [],
   "source": [
    "df_ = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkBTF2Hq8O_s",
    "outputId": "0de0842d-ffce-43e7-83cf-4e4bed3a625e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.33 s, sys: 10.3 ms, total: 7.34 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "df_[\"Top N\"] = df_[\"preproc_text\"].apply(get_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYzKIysR8aLa",
    "outputId": "148ffe90-0e9c-4b0a-d42d-97a5456659e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 s, sys: 136 ms, total: 24.2 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "cv=CountVectorizer(max_df=0.95,         # ignore words that appear in 95% of documents\n",
    "                   max_features=10000,  # the size of the vocabulary\n",
    "                   ngram_range=(1,3)    # vocabulary contains single words, bigrams, trigrams\n",
    "                  )\n",
    "\n",
    "cv.fit_transform(df_[\"preproc_text\"])\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "\n",
    "df_[\"Top_N_TF-IDF\"] = df_[\"preproc_text\"].apply(get_keywords, top_N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pADMMJ0K81Wx",
    "outputId": "1bc62739-d106-4ab7-d3ec-67a5e3394912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 59s, sys: 1min 53s, total: 5min 52s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "df_[\"Top_N_KeyBERT_1\"] = df_[\"preproc_text\"].apply(kw_model.extract_keywords, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3v7vMilKRer",
    "outputId": "cfdcbab9-c49d-4e6c-8277-79ac55857c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods : [Raw counts, Tf-Idf, KeyBERT]\n",
      "Computation times : [0.02849389 0.09536732 0.87613879]\n",
      "Keywords quality : [0.37879807 0.37003572 0.25116621]\n",
      "Quality scores : [ 0.36455112  0.32235206 -0.18690318]\n"
     ]
    }
   ],
   "source": [
    "computation_times = np.array([7.35, 24.6, 226], dtype=\"float\")\n",
    "computation_times /= sum(computation_times)\n",
    "\n",
    "keywords_quality = np.array([], dtype=\"float\")\n",
    "keywords_quality = np.append(keywords_quality, get_keywords_quality(df_, \"Top N\"))\n",
    "keywords_quality = np.append(keywords_quality, get_keywords_quality(df_, \"Top_N_TF-IDF\"))\n",
    "keywords_quality = np.append(keywords_quality, get_keywords_quality(df_, \"Top_N_KeyBERT_1\"))\n",
    "\n",
    "keywords_quality /= sum(keywords_quality)\n",
    "\n",
    "quality_scores = keywords_quality - 0.5 * computation_times\n",
    "\n",
    "print(\"Methods : [Raw counts, Tf-Idf, KeyBERT]\")\n",
    "print(\"Computation times : \" + str(computation_times))\n",
    "print(\"Keywords quality : \" + str(keywords_quality))\n",
    "print(\"Quality scores : \" + str(quality_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhS_Y6qgqW4Z"
   },
   "source": [
    "# Part 2. Word Vectors (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kedMB9f-qsnw",
    "outputId": "0c4504d3-c036-43c7-cb27-8393757f327c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5S4yJ_ZrHAo"
   },
   "source": [
    "Word Vectors are often used as a fundamental component for downstream NLP tasks, e.g. question answering, text generation, translation, etc., so it is important to build some intuitions as to their strengths and weaknesses. Here, you will explore two types of word vectors: those derived from co-occurrence matrices, and those derived via GloVe.\n",
    "\n",
    "Note on Terminology: The terms \"word vectors\" and \"word embeddings\" are often used interchangeably. The term \"embedding\" refers to the fact that we are encoding aspects of a word's meaning in a lower dimensional space. As Wikipedia states, \"conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKcD1SUIrP_m"
   },
   "source": [
    "## Count-Based Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Uvm6lbSsFD0"
   },
   "source": [
    "Most word vector models start from the following idea:\n",
    "\n",
    "You shall know a word by the company it keeps (Firth, J. R. 1957:11)\n",
    "\n",
    "Many word vector implementations are driven by the idea that similar words, i.e., (near) synonyms, will be used in similar contexts. As a result, similar words will often be spoken or written along with a shared subset of words, i.e., contexts. By examining these contexts, we can try to develop embeddings for our words. With this intuition in mind, many \"old school\" approaches to constructing word vectors relied on word counts. Here we elaborate upon one of those strategies, co-occurrence matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vMxbozcslLA"
   },
   "source": [
    "## Plotting Co-Occurrence Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3OO_oowsrK2"
   },
   "source": [
    "\n",
    "Here, we will be using the Reuters (business and financial news) corpus. If you haven't run the import cell at the top of this page, please run it now (click it and press SHIFT-RETURN). The corpus consists of 10,788 news documents totaling 1.3 million words. These documents span 90 categories and are split into train and test. For more details, please see https://www.nltk.org/book/ch02.html. We provide a read_corpus function below that pulls out only articles from the \"crude\" (i.e. news articles about oil, gas, etc.) category. The function also adds <START> and <END> tokens to each of the documents, and lowercases words. You do not have to perform any other kind of pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xTQwympsqDq"
   },
   "outputs": [],
   "source": [
    "def read_corpus(category=\"crude\"):\n",
    "    \"\"\" Read files from the specified Reuter's category.\n",
    "        Params:\n",
    "            category (string): category name\n",
    "        Return:\n",
    "            list of lists, with words from each of the processed files\n",
    "    \"\"\"\n",
    "    files = reuters.fileids(category)\n",
    "    return [[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQrwL93ns1Qy"
   },
   "source": [
    "Let's have a look what these documents are like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eZvFI3Qs0x4",
    "outputId": "a52652cb-0b2b-4770-c4ff-8f4f32ecfbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<START>', 'japan', 'to', 'revise', 'long', '-', 'term', 'energy', 'demand', 'downwards', 'the',\n",
      "  'ministry', 'of', 'international', 'trade', 'and', 'industry', '(', 'miti', ')', 'will', 'revise',\n",
      "  'its', 'long', '-', 'term', 'energy', 'supply', '/', 'demand', 'outlook', 'by', 'august', 'to',\n",
      "  'meet', 'a', 'forecast', 'downtrend', 'in', 'japanese', 'energy', 'demand', ',', 'ministry',\n",
      "  'officials', 'said', '.', 'miti', 'is', 'expected', 'to', 'lower', 'the', 'projection', 'for',\n",
      "  'primary', 'energy', 'supplies', 'in', 'the', 'year', '2000', 'to', '550', 'mln', 'kilolitres',\n",
      "  '(', 'kl', ')', 'from', '600', 'mln', ',', 'they', 'said', '.', 'the', 'decision', 'follows',\n",
      "  'the', 'emergence', 'of', 'structural', 'changes', 'in', 'japanese', 'industry', 'following',\n",
      "  'the', 'rise', 'in', 'the', 'value', 'of', 'the', 'yen', 'and', 'a', 'decline', 'in', 'domestic',\n",
      "  'electric', 'power', 'demand', '.', 'miti', 'is', 'planning', 'to', 'work', 'out', 'a', 'revised',\n",
      "  'energy', 'supply', '/', 'demand', 'outlook', 'through', 'deliberations', 'of', 'committee',\n",
      "  'meetings', 'of', 'the', 'agency', 'of', 'natural', 'resources', 'and', 'energy', ',', 'the',\n",
      "  'officials', 'said', '.', 'they', 'said', 'miti', 'will', 'also', 'review', 'the', 'breakdown',\n",
      "  'of', 'energy', 'supply', 'sources', ',', 'including', 'oil', ',', 'nuclear', ',', 'coal', 'and',\n",
      "  'natural', 'gas', '.', 'nuclear', 'energy', 'provided', 'the', 'bulk', 'of', 'japan', \"'\", 's',\n",
      "  'electric', 'power', 'in', 'the', 'fiscal', 'year', 'ended', 'march', '31', ',', 'supplying',\n",
      "  'an', 'estimated', '27', 'pct', 'on', 'a', 'kilowatt', '/', 'hour', 'basis', ',', 'followed',\n",
      "  'by', 'oil', '(', '23', 'pct', ')', 'and', 'liquefied', 'natural', 'gas', '(', '21', 'pct', '),',\n",
      "  'they', 'noted', '.', '<END>'],\n",
      " ['<START>', 'energy', '/', 'u', '.', 's', '.', 'petrochemical', 'industry', 'cheap', 'oil',\n",
      "  'feedstocks', ',', 'the', 'weakened', 'u', '.', 's', '.', 'dollar', 'and', 'a', 'plant',\n",
      "  'utilization', 'rate', 'approaching', '90', 'pct', 'will', 'propel', 'the', 'streamlined', 'u',\n",
      "  '.', 's', '.', 'petrochemical', 'industry', 'to', 'record', 'profits', 'this', 'year', ',',\n",
      "  'with', 'growth', 'expected', 'through', 'at', 'least', '1990', ',', 'major', 'company',\n",
      "  'executives', 'predicted', '.', 'this', 'bullish', 'outlook', 'for', 'chemical', 'manufacturing',\n",
      "  'and', 'an', 'industrywide', 'move', 'to', 'shed', 'unrelated', 'businesses', 'has', 'prompted',\n",
      "  'gaf', 'corp', '&', 'lt', ';', 'gaf', '>,', 'privately', '-', 'held', 'cain', 'chemical', 'inc',\n",
      "  ',', 'and', 'other', 'firms', 'to', 'aggressively', 'seek', 'acquisitions', 'of', 'petrochemical',\n",
      "  'plants', '.', 'oil', 'companies', 'such', 'as', 'ashland', 'oil', 'inc', '&', 'lt', ';', 'ash',\n",
      "  '>,', 'the', 'kentucky', '-', 'based', 'oil', 'refiner', 'and', 'marketer', ',', 'are', 'also',\n",
      "  'shopping', 'for', 'money', '-', 'making', 'petrochemical', 'businesses', 'to', 'buy', '.', '\"',\n",
      "  'i', 'see', 'us', 'poised', 'at', 'the', 'threshold', 'of', 'a', 'golden', 'period', ',\"', 'said',\n",
      "  'paul', 'oreffice', ',', 'chairman', 'of', 'giant', 'dow', 'chemical', 'co', '&', 'lt', ';',\n",
      "  'dow', '>,', 'adding', ',', '\"', 'there', \"'\", 's', 'no', 'major', 'plant', 'capacity', 'being',\n",
      "  'added', 'around', 'the', 'world', 'now', '.', 'the', 'whole', 'game', 'is', 'bringing', 'out',\n",
      "  'new', 'products', 'and', 'improving', 'the', 'old', 'ones', '.\"', 'analysts', 'say', 'the',\n",
      "  'chemical', 'industry', \"'\", 's', 'biggest', 'customers', ',', 'automobile', 'manufacturers',\n",
      "  'and', 'home', 'builders', 'that', 'use', 'a', 'lot', 'of', 'paints', 'and', 'plastics', ',',\n",
      "  'are', 'expected', 'to', 'buy', 'quantities', 'this', 'year', '.', 'u', '.', 's', '.',\n",
      "  'petrochemical', 'plants', 'are', 'currently', 'operating', 'at', 'about', '90', 'pct',\n",
      "  'capacity', ',', 'reflecting', 'tighter', 'supply', 'that', 'could', 'hike', 'product', 'prices',\n",
      "  'by', '30', 'to', '40', 'pct', 'this', 'year', ',', 'said', 'john', 'dosher', ',', 'managing',\n",
      "  'director', 'of', 'pace', 'consultants', 'inc', 'of', 'houston', '.', 'demand', 'for', 'some',\n",
      "  'products', 'such', 'as', 'styrene', 'could', 'push', 'profit', 'margins', 'up', 'by', 'as',\n",
      "  'much', 'as', '300', 'pct', ',', 'he', 'said', '.', 'oreffice', ',', 'speaking', 'at', 'a',\n",
      "  'meeting', 'of', 'chemical', 'engineers', 'in', 'houston', ',', 'said', 'dow', 'would', 'easily',\n",
      "  'top', 'the', '741', 'mln', 'dlrs', 'it', 'earned', 'last', 'year', 'and', 'predicted', 'it',\n",
      "  'would', 'have', 'the', 'best', 'year', 'in', 'its', 'history', '.', 'in', '1985', ',', 'when',\n",
      "  'oil', 'prices', 'were', 'still', 'above', '25', 'dlrs', 'a', 'barrel', 'and', 'chemical',\n",
      "  'exports', 'were', 'adversely', 'affected', 'by', 'the', 'strong', 'u', '.', 's', '.', 'dollar',\n",
      "  ',', 'dow', 'had', 'profits', 'of', '58', 'mln', 'dlrs', '.', '\"', 'i', 'believe', 'the',\n",
      "  'entire', 'chemical', 'industry', 'is', 'headed', 'for', 'a', 'record', 'year', 'or', 'close',\n",
      "  'to', 'it', ',\"', 'oreffice', 'said', '.', 'gaf', 'chairman', 'samuel', 'heyman', 'estimated',\n",
      "  'that', 'the', 'u', '.', 's', '.', 'chemical', 'industry', 'would', 'report', 'a', '20', 'pct',\n",
      "  'gain', 'in', 'profits', 'during', '1987', '.', 'last', 'year', ',', 'the', 'domestic',\n",
      "  'industry', 'earned', 'a', 'total', 'of', '13', 'billion', 'dlrs', ',', 'a', '54', 'pct', 'leap',\n",
      "  'from', '1985', '.', 'the', 'turn', 'in', 'the', 'fortunes', 'of', 'the', 'once', '-', 'sickly',\n",
      "  'chemical', 'industry', 'has', 'been', 'brought', 'about', 'by', 'a', 'combination', 'of', 'luck',\n",
      "  'and', 'planning', ',', 'said', 'pace', \"'\", 's', 'john', 'dosher', '.', 'dosher', 'said', 'last',\n",
      "  'year', \"'\", 's', 'fall', 'in', 'oil', 'prices', 'made', 'feedstocks', 'dramatically', 'cheaper',\n",
      "  'and', 'at', 'the', 'same', 'time', 'the', 'american', 'dollar', 'was', 'weakening', 'against',\n",
      "  'foreign', 'currencies', '.', 'that', 'helped', 'boost', 'u', '.', 's', '.', 'chemical',\n",
      "  'exports', '.', 'also', 'helping', 'to', 'bring', 'supply', 'and', 'demand', 'into', 'balance',\n",
      "  'has', 'been', 'the', 'gradual', 'market', 'absorption', 'of', 'the', 'extra', 'chemical',\n",
      "  'manufacturing', 'capacity', 'created', 'by', 'middle', 'eastern', 'oil', 'producers', 'in',\n",
      "  'the', 'early', '1980s', '.', 'finally', ',', 'virtually', 'all', 'major', 'u', '.', 's', '.',\n",
      "  'chemical', 'manufacturers', 'have', 'embarked', 'on', 'an', 'extensive', 'corporate',\n",
      "  'restructuring', 'program', 'to', 'mothball', 'inefficient', 'plants', ',', 'trim', 'the',\n",
      "  'payroll', 'and', 'eliminate', 'unrelated', 'businesses', '.', 'the', 'restructuring', 'touched',\n",
      "  'off', 'a', 'flurry', 'of', 'friendly', 'and', 'hostile', 'takeover', 'attempts', '.', 'gaf', ',',\n",
      "  'which', 'made', 'an', 'unsuccessful', 'attempt', 'in', '1985', 'to', 'acquire', 'union',\n",
      "  'carbide', 'corp', '&', 'lt', ';', 'uk', '>,', 'recently', 'offered', 'three', 'billion', 'dlrs',\n",
      "  'for', 'borg', 'warner', 'corp', '&', 'lt', ';', 'bor', '>,', 'a', 'chicago', 'manufacturer',\n",
      "  'of', 'plastics', 'and', 'chemicals', '.', 'another', 'industry', 'powerhouse', ',', 'w', '.',\n",
      "  'r', '.', 'grace', '&', 'lt', ';', 'gra', '>', 'has', 'divested', 'its', 'retailing', ',',\n",
      "  'restaurant', 'and', 'fertilizer', 'businesses', 'to', 'raise', 'cash', 'for', 'chemical',\n",
      "  'acquisitions', '.', 'but', 'some', 'experts', 'worry', 'that', 'the', 'chemical', 'industry',\n",
      "  'may', 'be', 'headed', 'for', 'trouble', 'if', 'companies', 'continue', 'turning', 'their',\n",
      "  'back', 'on', 'the', 'manufacturing', 'of', 'staple', 'petrochemical', 'commodities', ',', 'such',\n",
      "  'as', 'ethylene', ',', 'in', 'favor', 'of', 'more', 'profitable', 'specialty', 'chemicals',\n",
      "  'that', 'are', 'custom', '-', 'designed', 'for', 'a', 'small', 'group', 'of', 'buyers', '.', '\"',\n",
      "  'companies', 'like', 'dupont', '&', 'lt', ';', 'dd', '>', 'and', 'monsanto', 'co', '&', 'lt', ';',\n",
      "  'mtc', '>', 'spent', 'the', 'past', 'two', 'or', 'three', 'years', 'trying', 'to', 'get', 'out',\n",
      "  'of', 'the', 'commodity', 'chemical', 'business', 'in', 'reaction', 'to', 'how', 'badly', 'the',\n",
      "  'market', 'had', 'deteriorated', ',\"', 'dosher', 'said', '.', '\"', 'but', 'i', 'think', 'they',\n",
      "  'will', 'eventually', 'kill', 'the', 'margins', 'on', 'the', 'profitable', 'chemicals', 'in',\n",
      "  'the', 'niche', 'market', '.\"', 'some', 'top', 'chemical', 'executives', 'share', 'the',\n",
      "  'concern', '.', '\"', 'the', 'challenge', 'for', 'our', 'industry', 'is', 'to', 'keep', 'from',\n",
      "  'getting', 'carried', 'away', 'and', 'repeating', 'past', 'mistakes', ',\"', 'gaf', \"'\", 's',\n",
      "  'heyman', 'cautioned', '.', '\"', 'the', 'shift', 'from', 'commodity', 'chemicals', 'may', 'be',\n",
      "  'ill', '-', 'advised', '.', 'specialty', 'businesses', 'do', 'not', 'stay', 'special', 'long',\n",
      "  '.\"', 'houston', '-', 'based', 'cain', 'chemical', ',', 'created', 'this', 'month', 'by', 'the',\n",
      "  'sterling', 'investment', 'banking', 'group', ',', 'believes', 'it', 'can', 'generate', '700',\n",
      "  'mln', 'dlrs', 'in', 'annual', 'sales', 'by', 'bucking', 'the', 'industry', 'trend', '.',\n",
      "  'chairman', 'gordon', 'cain', ',', 'who', 'previously', 'led', 'a', 'leveraged', 'buyout', 'of',\n",
      "  'dupont', \"'\", 's', 'conoco', 'inc', \"'\", 's', 'chemical', 'business', ',', 'has', 'spent', '1',\n",
      "  '.', '1', 'billion', 'dlrs', 'since', 'january', 'to', 'buy', 'seven', 'petrochemical', 'plants',\n",
      "  'along', 'the', 'texas', 'gulf', 'coast', '.', 'the', 'plants', 'produce', 'only', 'basic',\n",
      "  'commodity', 'petrochemicals', 'that', 'are', 'the', 'building', 'blocks', 'of', 'specialty',\n",
      "  'products', '.', '\"', 'this', 'kind', 'of', 'commodity', 'chemical', 'business', 'will', 'never',\n",
      "  'be', 'a', 'glamorous', ',', 'high', '-', 'margin', 'business', ',\"', 'cain', 'said', ',',\n",
      "  'adding', 'that', 'demand', 'is', 'expected', 'to', 'grow', 'by', 'about', 'three', 'pct',\n",
      "  'annually', '.', 'garo', 'armen', ',', 'an', 'analyst', 'with', 'dean', 'witter', 'reynolds', ',',\n",
      "  'said', 'chemical', 'makers', 'have', 'also', 'benefitted', 'by', 'increasing', 'demand', 'for',\n",
      "  'plastics', 'as', 'prices', 'become', 'more', 'competitive', 'with', 'aluminum', ',', 'wood',\n",
      "  'and', 'steel', 'products', '.', 'armen', 'estimated', 'the', 'upturn', 'in', 'the', 'chemical',\n",
      "  'business', 'could', 'last', 'as', 'long', 'as', 'four', 'or', 'five', 'years', ',', 'provided',\n",
      "  'the', 'u', '.', 's', '.', 'economy', 'continues', 'its', 'modest', 'rate', 'of', 'growth', '.',\n",
      "  '<END>'],\n",
      " ['<START>', 'turkey', 'calls', 'for', 'dialogue', 'to', 'solve', 'dispute', 'turkey', 'said',\n",
      "  'today', 'its', 'disputes', 'with', 'greece', ',', 'including', 'rights', 'on', 'the',\n",
      "  'continental', 'shelf', 'in', 'the', 'aegean', 'sea', ',', 'should', 'be', 'solved', 'through',\n",
      "  'negotiations', '.', 'a', 'foreign', 'ministry', 'statement', 'said', 'the', 'latest', 'crisis',\n",
      "  'between', 'the', 'two', 'nato', 'members', 'stemmed', 'from', 'the', 'continental', 'shelf',\n",
      "  'dispute', 'and', 'an', 'agreement', 'on', 'this', 'issue', 'would', 'effect', 'the', 'security',\n",
      "  ',', 'economy', 'and', 'other', 'rights', 'of', 'both', 'countries', '.', '\"', 'as', 'the',\n",
      "  'issue', 'is', 'basicly', 'political', ',', 'a', 'solution', 'can', 'only', 'be', 'found', 'by',\n",
      "  'bilateral', 'negotiations', ',\"', 'the', 'statement', 'said', '.', 'greece', 'has', 'repeatedly',\n",
      "  'said', 'the', 'issue', 'was', 'legal', 'and', 'could', 'be', 'solved', 'at', 'the',\n",
      "  'international', 'court', 'of', 'justice', '.', 'the', 'two', 'countries', 'approached', 'armed',\n",
      "  'confrontation', 'last', 'month', 'after', 'greece', 'announced', 'it', 'planned', 'oil',\n",
      "  'exploration', 'work', 'in', 'the', 'aegean', 'and', 'turkey', 'said', 'it', 'would', 'also',\n",
      "  'search', 'for', 'oil', '.', 'a', 'face', '-', 'off', 'was', 'averted', 'when', 'turkey',\n",
      "  'confined', 'its', 'research', 'to', 'territorrial', 'waters', '.', '\"', 'the', 'latest',\n",
      "  'crises', 'created', 'an', 'historic', 'opportunity', 'to', 'solve', 'the', 'disputes', 'between',\n",
      "  'the', 'two', 'countries', ',\"', 'the', 'foreign', 'ministry', 'statement', 'said', '.', 'turkey',\n",
      "  \"'\", 's', 'ambassador', 'in', 'athens', ',', 'nazmi', 'akiman', ',', 'was', 'due', 'to', 'meet',\n",
      "  'prime', 'minister', 'andreas', 'papandreou', 'today', 'for', 'the', 'greek', 'reply', 'to', 'a',\n",
      "  'message', 'sent', 'last', 'week', 'by', 'turkish', 'prime', 'minister', 'turgut', 'ozal', '.',\n",
      "  'the', 'contents', 'of', 'the', 'message', 'were', 'not', 'disclosed', '.', '<END>']]\n"
     ]
    }
   ],
   "source": [
    "reuters_corpus = read_corpus()\n",
    "pprint.pprint(reuters_corpus[:3], compact=True, width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNKy6j3as7xJ"
   },
   "source": [
    "### Question 2.1: Implement distinct_words [code] (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIgkQ47otdqZ"
   },
   "source": [
    "Write a method to work out the distinct words (word types) that occur in the corpus. You can do this with for loops, but it's more efficient to do it with Python list comprehensions. In particular, this may be useful to flatten a list of lists. If you're not familiar with Python list comprehensions in general, here's more information.\n",
    "\n",
    "Your returned corpus_words should be sorted. You can use python's sorted function for this.\n",
    "\n",
    "You may find it useful to use Python sets to remove duplicate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTIH5vFetgjD"
   },
   "outputs": [],
   "source": [
    "def distinct_words(corpus):\n",
    "    \"\"\" Determine a list of distinct words for the corpus.\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents - eg [[\"hey\", \"I\", \"am\", \"toto\"], [\"hey\", \"I\", \"am\", \"tata\"]]\n",
    "        Return:\n",
    "            corpus_words (list of strings): sorted list of distinct words across the corpus\n",
    "            num_corpus_words (integer): number of distinct words across the corpus\n",
    "    \"\"\"\n",
    "    corpus_words = []\n",
    "    num_corpus_words = -1\n",
    "    \n",
    "    # ------------------\n",
    "    # Write your implementation here.w\n",
    "    corpus_words = sorted(list(set([word for doc in corpus for word in doc])))\n",
    "    num_corpus_words = len(corpus_words)\n",
    "\n",
    "    # ------------------\n",
    "\n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZX4dH8stmYN",
    "outputId": "6953f2f3-b816-45f4-fcec-80ca4c2ca732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this not an exhaustive check for correctness.\n",
    "# ---------------------\n",
    "\n",
    "# Define toy corpus\n",
    "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
    "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
    "\n",
    "# Correct answers\n",
    "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
    "ans_num_corpus_words = len(ans_test_corpus_words)\n",
    "\n",
    "# Test correct number of words\n",
    "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
    "\n",
    "# Test correct words\n",
    "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:   {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
    "\n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86fD2hYr3fw8"
   },
   "source": [
    "### Question 2.2: Implement compute_co_occurrence_matrix [code] (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE4MLCIa3lKw"
   },
   "source": [
    "Write a method that constructs a co-occurrence matrix for a certain window-size  n  (with a default of 4), considering words  n  before and  n  after the word in the center of the window. Here, we start to use numpy (np) to represent vectors, matrices, and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zz5vrGb43lbA"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter \n",
    "\n",
    "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
    "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "    \n",
    "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "              number of co-occurring words.\n",
    "              \n",
    "              For example, if we take the document \"<START> All that glitters is not gold <END>\" with window size of 4,\n",
    "              \"All\" will co-occur with \"<START>\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "    \n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "            window_size (int): size of context window\n",
    "        Return:\n",
    "            M (a symmetric numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): \n",
    "                Co-occurence matrix of word counts. \n",
    "                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "            word2ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
    "    \"\"\"\n",
    "    words, num_words = distinct_words(corpus)\n",
    "    M = None\n",
    "    word2ind = {}\n",
    "    \n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    for i in range(num_words) :\n",
    "      word2ind[words[i]] = i\n",
    "    \n",
    "    M = np.zeros((num_words, num_words))\n",
    "\n",
    "    for document in corpus :\n",
    "    \n",
    "      doc_length = len(document)\n",
    "    \n",
    "      for i in range(doc_length) :\n",
    "    \n",
    "        min_idx = max(0, i - window_size)\n",
    "    \n",
    "        for j in range(min_idx, i) :\n",
    "          M[word2ind[document[i]], word2ind[document[j]]] += 1\n",
    "          M[word2ind[document[j]], word2ind[document[i]]] += 1\n",
    "    # ------------------\n",
    "\n",
    "    return M, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guUdCsM2BUuC",
    "outputId": "5b5d8683-237f-4efc-f253-6840ec5d749b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this is not an exhaustive check for correctness.\n",
    "# ---------------------\n",
    "\n",
    "# Define toy corpus and get student's co-occurrence matrix\n",
    "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
    "M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
    "\n",
    "# Correct M and word2ind\n",
    "M_test_ans = np.array( \n",
    "    [[0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,],\n",
    "     [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,],\n",
    "     [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,],\n",
    "     [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,],\n",
    "     [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,],\n",
    "     [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,],\n",
    "     [1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,],\n",
    "     [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,],\n",
    "     [0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,],\n",
    "     [1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,]]\n",
    ")\n",
    "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
    "word2ind_ans = dict(zip(ans_test_corpus_words, range(len(ans_test_corpus_words))))\n",
    "\n",
    "# Test correct word2ind\n",
    "assert (word2ind_ans == word2ind_test), \"Your word2ind is incorrect:\\nCorrect: {}\\nYours: {}\".format(word2ind_ans, word2ind_test)\n",
    "\n",
    "# Test correct M shape\n",
    "assert (M_test.shape == M_test_ans.shape), \"M matrix has incorrect shape.\\nCorrect: {}\\nYours: {}\".format(M_test.shape, M_test_ans.shape)\n",
    "\n",
    "# Test correct M values\n",
    "for w1 in word2ind_ans.keys():\n",
    "    idx1 = word2ind_ans[w1]\n",
    "    for w2 in word2ind_ans.keys():\n",
    "        idx2 = word2ind_ans[w2]\n",
    "        student = M_test[idx1, idx2]\n",
    "        correct = M_test_ans[idx1, idx2]\n",
    "        if student != correct:\n",
    "            print(\"Correct M:\")\n",
    "            print(M_test_ans)\n",
    "            print(\"Your M: \")\n",
    "            print(M_test)\n",
    "            raise AssertionError(\"Incorrect count at index ({}, {})=({}, {}) in matrix M. Yours has {} but should have {}.\".format(idx1, idx2, w1, w2, student, correct))\n",
    "\n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCC24T0WPyI2"
   },
   "source": [
    "### Question 2.3: Implement reduce_to_k_dim [code] (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ9XXG-WP2dZ"
   },
   "source": [
    "Construct a method that performs dimensionality reduction on the matrix to produce k-dimensional embeddings. Use SVD to take the top k components and produce a new matrix of k-dimensional embeddings.\n",
    "\n",
    "Note: All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but only scipy and sklearn provide an implementation of Truncated SVD, and only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD. So please use sklearn.decomposition.TruncatedSVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jfqvOUOP8R6"
   },
   "outputs": [],
   "source": [
    "def reduce_to_k_dim(M, k=2):\n",
    "    \"\"\" Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
    "        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
    "            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "    \n",
    "        Params:\n",
    "            M (numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): co-occurence matrix of word counts\n",
    "            k (int): embedding size of each word after dimension reduction\n",
    "        Return:\n",
    "            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
    "                    In terms of the SVD from math class, this actually returns U * S\n",
    "    \"\"\"    \n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "    \n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=n_iters)\n",
    "    M_reduced = svd.fit_transform(M)\n",
    "    \n",
    "    # ------------------\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rGeaWNuRAnJ",
    "outputId": "8accc82f-fb94-410b-9e58-19c46753217b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 10 words...\n",
      "Done.\n",
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this is not an exhaustive check for correctness \n",
    "# In fact we only check that your M_reduced has the right dimensions.\n",
    "# ---------------------\n",
    "\n",
    "# Define toy corpus and run student code\n",
    "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
    "M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
    "M_test_reduced = reduce_to_k_dim(M_test, k=2)\n",
    "\n",
    "# Test proper dimensions\n",
    "assert (M_test_reduced.shape[0] == 10), \"M_reduced has {} rows; should have {}\".format(M_test_reduced.shape[0], 10)\n",
    "assert (M_test_reduced.shape[1] == 2), \"M_reduced has {} columns; should have {}\".format(M_test_reduced.shape[1], 2)\n",
    "\n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iTgMaquRQKB"
   },
   "source": [
    "### Question 2.4: Implement plot_embeddings [code] (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H629WACPRTg2"
   },
   "source": [
    "Here you will write a function to plot a set of 2D vectors in 2D space. For graphs, we will use Matplotlib (plt).\n",
    "\n",
    "For this example, you may find it useful to adapt this code. In the future, a good way to make a plot is to look at the Matplotlib gallery, find a plot that looks somewhat like what you want, and adapt the code they give."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMfaxKfERT1P"
   },
   "outputs": [],
   "source": [
    "def plot_embeddings(M_reduced, word2ind, words):\n",
    "    \"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
    "        NOTE: do not plot all the words listed in M_reduced / word2ind.\n",
    "        Include a label next to each point.\n",
    "        \n",
    "        Params:\n",
    "            M_reduced (numpy matrix of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal word embeddings\n",
    "            word2ind (dict): dictionary that maps word to indices for matrix M\n",
    "            words (list of strings): words whose embeddings we want to visualize\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    xs = []\n",
    "    ys = []\n",
    "    labels = []\n",
    "\n",
    "    for word in words :\n",
    "      corresponding_embedding = M_reduced[word2ind[word]]\n",
    "      xs.append(corresponding_embedding[0])\n",
    "      ys.append(corresponding_embedding[1])\n",
    "      labels.append(word)\n",
    "    \n",
    "    plt.scatter(xs, ys)\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "      plt.annotate(label, (xs[i], ys[i]))\n",
    "\n",
    "    # ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "bJ5sOXmXRYOa",
    "outputId": "b3a5f8e1-f2f6-4da0-be1f-a7829903d038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Outputted Plot:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this is not an exhaustive check for correctness.\n",
    "# The plot produced should look like the \"test solution plot\" depicted below. \n",
    "# ---------------------\n",
    "\n",
    "print (\"-\" * 80)\n",
    "print (\"Outputted Plot:\")\n",
    "\n",
    "M_reduced_plot_test = np.array([[1, 1], [-1, -1], [1, -1], [-1, 1], [0, 0]])\n",
    "word2ind_plot_test = {'test1': 0, 'test2': 1, 'test3': 2, 'test4': 3, 'test5': 4}\n",
    "words = ['test1', 'test2', 'test3', 'test4', 'test5']\n",
    "plot_embeddings(M_reduced_plot_test, word2ind_plot_test, words)\n",
    "\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRb0HnWqVCDL"
   },
   "source": [
    "### Question 2.5: Co-Occurrence Plot Analysis [written] (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkfAWdLFVFx-"
   },
   "source": [
    "Now we will put together all the parts you have written! We will compute the co-occurrence matrix with fixed window of 4 (the default window size), over the Reuters \"crude\" (oil) corpus. Then we will use TruncatedSVD to compute 2-dimensional embeddings of each word. TruncatedSVD returns U*S, so we need to normalize the returned vectors, so that all the vectors will appear around the unit circle (therefore closeness is directional closeness). Note: The line of code below that does the normalizing uses the NumPy concept of broadcasting. If you don't know about broadcasting, check out Computation on Arrays: Broadcasting by Jake VanderPlas.\n",
    "\n",
    "Run the below cell to produce the plot. It'll probably take a few seconds to run. What clusters together in 2-dimensional embedding space? What doesn't cluster together that you might think should have? Note: \"bpd\" stands for \"barrels per day\" and is a commonly used abbreviation in crude oil topic articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "R3d0UK2iVFDM",
    "outputId": "5bb3f1d0-64eb-43b4-a3ae-3b6de6a03485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 8185 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Run This Cell to Produce Your Plot\n",
    "# ------------------------------\n",
    "reuters_corpus = read_corpus()\n",
    "M_co_occurrence, word2ind_co_occurrence = compute_co_occurrence_matrix(reuters_corpus)\n",
    "M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=2)\n",
    "\n",
    "# Rescale (normalize) the rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=1)\n",
    "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # broadcasting\n",
    "\n",
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']\n",
    "\n",
    "plot_embeddings(M_normalized, word2ind_co_occurrence, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkN1EV_7Mx_V"
   },
   "source": [
    "We have a clear cluster for country names, such as \"iraq, ecuador, kuwait\" which is normal. We can also see that \"petroleum\" and \"industry\" are very close, which makes sense as \"petroleum industry\" is a common phrase. However we see that \"bpd (barrels per day)\" and \"barrels\" are far apart even though intuitively they should be close, both referring to barrels. This means they may actually be used in different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQg7l284V0oa"
   },
   "source": [
    "# Part 3. Prediction-based word vectors (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSNq-K6UzzDP"
   },
   "source": [
    "As discussed in class, more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). If you're feeling adventurous, challenge yourself and try reading GloVe's original paper.\n",
    "\n",
    "Then run the following cells to load the GloVe vectors into memory. Note: If this is your first time to run these cells, i.e. download the embedding model, it will take a couple minutes to run. If you've run these cells before, rerunning them will load the model without redownloading it, which will take about 1 to 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqq7A2IWz011"
   },
   "outputs": [],
   "source": [
    "def load_embedding_model():\n",
    "    \"\"\" Load GloVe Vectors\n",
    "        Return:\n",
    "            wv_from_bin: All 400000 embeddings, each lengh 200\n",
    "    \"\"\"\n",
    "    import gensim.downloader as api\n",
    "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
    "    print(\"Loaded vocab size %i\" % len(wv_from_bin.vocab.keys()))\n",
    "    return wv_from_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYbJ59Jiz7OA",
    "outputId": "5886d03d-4ff4-46bc-f0e0-13102499c8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 252.1/252.1MB downloaded\n",
      "Loaded vocab size 400000\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Run Cell to Load Word Vectors\n",
    "# Note: This will take a couple minutes\n",
    "# -----------------------------------\n",
    "wv_from_bin = load_embedding_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edzctdyh0rDm"
   },
   "source": [
    "#### Note: If you are receiving a \"reset by peer\" error, rerun the cell to restart the download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbGSRVPxjaT_"
   },
   "source": [
    "## Reducing dimensionality of Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXr1zGXSjddn"
   },
   "source": [
    "Let's directly compare the GloVe embeddings to those of the co-occurrence matrix. In order to avoid running out of memory, we will work with a sample of 10000 GloVe vectors instead. Run the following cells to:\n",
    "\n",
    "Put 10000 Glove vectors into a matrix M\n",
    "Run reduce_to_k_dim (your Truncated SVD function) to reduce the vectors from 200-dimensional to 2-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_xj1ApzjfOr"
   },
   "outputs": [],
   "source": [
    "def get_matrix_of_vectors(wv_from_bin, required_words=['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']):\n",
    "    \"\"\" Put the GloVe vectors into a matrix M.\n",
    "        Param:\n",
    "            wv_from_bin: KeyedVectors object; the 400000 GloVe vectors loaded from file\n",
    "        Return:\n",
    "            M: numpy matrix shape (num words, 200) containing the vectors\n",
    "            word2ind: dictionary mapping each word to its row number in M\n",
    "    \"\"\"\n",
    "    import random\n",
    "    words = list(wv_from_bin.vocab.keys())\n",
    "    print(\"Shuffling words ...\")\n",
    "    random.seed(224)\n",
    "    random.shuffle(words)\n",
    "    words = words[:10000]\n",
    "    print(\"Putting %i words into word2ind and matrix M...\" % len(words))\n",
    "    word2ind = {}\n",
    "    M = []\n",
    "    curInd = 0\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(wv_from_bin.word_vec(w))\n",
    "            word2ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    for w in required_words:\n",
    "        if w in words:\n",
    "            continue\n",
    "        try:\n",
    "            M.append(wv_from_bin.word_vec(w))\n",
    "            word2ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    M = np.stack(M)\n",
    "    print(\"Done.\")\n",
    "    return M, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHVTZLiBjhN5",
    "outputId": "653eb188-66aa-47e6-9ffb-54d9b6ceb445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling words ...\n",
      "Putting 10000 words into word2ind and matrix M...\n",
      "Done.\n",
      "Running Truncated SVD over 10010 words...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Run Cell to Reduce 200-Dimensional Word Embeddings to k Dimensions\n",
    "# Note: This should be quick to run\n",
    "# -----------------------------------------------------------------\n",
    "M, word2ind = get_matrix_of_vectors(wv_from_bin)\n",
    "M_reduced = reduce_to_k_dim(M, k=2)\n",
    "\n",
    "# Rescale (normalize) the rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced, axis=1)\n",
    "M_reduced_normalized = M_reduced / M_lengths[:, np.newaxis] # broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdoZKWxijmHk"
   },
   "source": [
    "### Question 3.1: GloVe Plot Analysis [written] (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyDIugqjjo3R"
   },
   "source": [
    "Run the cell below to plot the 2D GloVe embeddings for ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq'].\n",
    "\n",
    "What clusters together in 2-dimensional embedding space? What doesn't cluster together that you think should have? How is the plot different from the one generated earlier from the co-occurrence matrix? What is a possible cause for the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "KK438bCgjm98",
    "outputId": "c4752cbb-67dd-4ecf-890f-cc2c4399c3cd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']\n",
    "plot_embeddings(M_reduced_normalized, word2ind, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39cCl0DQjuJN"
   },
   "source": [
    "Now the main clusters are \"iraq, ecuador, petroleum\" and \"industry, energy\". \"barrels\" and \"bpd\" still do not form a cluster, confirming our previous intuition. This plot is different from the previous one, for example \"industry\" is now closer to \"energy\" than to \"petroleum\". This may be explained to the fact that GloVe is finer in learning his embedding to represent semantic meaning from the co-occurence matrix. The dataset used for the training of GloVe is probably way bigger and more generalist than the reuters corpus, which may also explain the differences (for example, \"energy industry\" may be more frequent than \"petroleum industry\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toHZ2o-Ljwwm"
   },
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBZbtLYzj1R_"
   },
   "source": [
    "Now that we have word vectors, we need a way to quantify the similarity between individual words, according to these vectors. One such metric is cosine-similarity. We will be using this to find words that are \"close\" and \"far\" from one another.\n",
    "\n",
    "We can think of n-dimensional vectors as points in n-dimensional space. If we take this perspective L1 and L2 Distances help quantify the amount of space \"we must travel\" to get between these two points. Another approach is to examine the angle between two vectors. From trigonometry we know that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLE4DOTNj69N"
   },
   "source": [
    "### Question 3.2: Words with Multiple Meanings (1.5 points) [code + written]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0LT0bH4kolN"
   },
   "source": [
    "Polysemes and homonyms are words that have more than one meaning (see this wiki page to learn more about the difference between polysemes and homonyms ). Find a word with at least two different meanings such that the top-10 most similar words (according to cosine similarity) contain related words from both meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one.\n",
    "\n",
    "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain one of the meanings of the words)?\n",
    "\n",
    "Note: You should use the wv_from_bin.most_similar(word) function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the GenSim documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgoE4V3rj76o",
    "outputId": "c1e35aa5-0917-4e54-83ea-106770ef5e75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mice', 0.6580958366394043),\n",
       " ('keyboard', 0.5548278093338013),\n",
       " ('rat', 0.5433950424194336),\n",
       " ('rabbit', 0.5192376971244812),\n",
       " ('cat', 0.5077415704727173),\n",
       " ('cursor', 0.5058691501617432),\n",
       " ('trackball', 0.5048903226852417),\n",
       " ('joystick', 0.4984104633331299),\n",
       " ('mickey', 0.47242850065231323),\n",
       " ('clicks', 0.4722806215286255)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------\n",
    "# Write your implementation here.\n",
    "example_word = \"mouse\"\n",
    "wv_from_bin.most_similar(example_word, topn=10)\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z90e-p_jktYD"
   },
   "source": [
    "When using \"mouse\" we can see that in the top-10 words some relate to \"mouse\" as an animal (\"mice\", \"rat\", \"rabbit\", \"mickey\") and some relate to \"mouse\" as the device to use a computer (\"keyboard\", \"cursor\", \"trackball\", \"clicks\"). Many polysemous and homonymic words don't show this tendency on the first top-10 words. This may be due to the fact that one meaning is often way more frequent than the other on polysemous and homonymic words, which would lead for the more frequent meaning to have a bigger representation in the co-occurence matrix and a clearer presence in the words with best similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBt1A0Y8kyqx"
   },
   "source": [
    "### Question 3.3: Synonyms & Antonyms (2 points) [code + written]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2gWr_Cvk3Tu"
   },
   "source": [
    "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
    "\n",
    "Find three words  (w1,w2,w3)  where  w1  and  w2  are synonyms and  w1  and  w3  are antonyms, but Cosine Distance  (w1,w3)<  Cosine Distance  (w1,w2) .\n",
    "\n",
    "As an example,  w1 =\"happy\" is closer to  w3 =\"sad\" than to  w2 =\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
    "\n",
    "You should use the the wv_from_bin.distance(w1, w2) function here in order to compute the cosine distance between two words. Please see the GenSim documentation for further assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRwHp4noktJF",
    "outputId": "05a932dc-d6e2-451d-ab98-874f7754be34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 : private, w2 : confidential, w3 : public\n",
      "w1-w2 distance : 0.6473133862018585\n",
      "w1-w3 distance : 0.293789803981781\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# Write your implementation here.\n",
    "w1 = \"private\"\n",
    "w2 = \"confidential\"\n",
    "w3 = \"public\"\n",
    "\n",
    "print(\"w1 : \" + str(w1) + \", w2 : \" + str(w2) + \", w3 : \" + str(w3))\n",
    "print(\"w1-w2 distance : \" + str(wv_from_bin.distance(w1,w2)))\n",
    "print(\"w1-w3 distance : \" + str(wv_from_bin.distance(w1,w3)))\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AD2asvrk7Y7"
   },
   "source": [
    "This counter-intuitive example may be explained by the fact that \"confidential\" is not as frequent as \"private\" and \"public\". These two words are also very frequently mentioned together as they are typical opposites (such as up and down, high and low, hot and cold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0uNtlXZlAdy"
   },
   "source": [
    "### Question 3.4: Analogies with Word Vectors [written] (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqKCiSDhlEBf"
   },
   "source": [
    "Word vectors have been shown to sometimes exhibit the ability to solve analogies.\n",
    "\n",
    "As an example, for the analogy \"man : king :: woman : x\" (read: man is to king as woman is to x), what is x?\n",
    "\n",
    "In the cell below, we show you how to use word vectors to find x using the most_similar function from the GenSim documentation. The function finds words that are most similar to the words in the positive list and most dissimilar from the words in the negative list (while omitting the input words, which are often the most similar; see this paper). The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHlsY4kolA6f",
    "outputId": "451f2e65-b272-413f-ebf9-7d361c14b01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.6978678703308105),\n",
      " ('princess', 0.6081745028495789),\n",
      " ('monarch', 0.5889754891395569),\n",
      " ('throne', 0.5775108933448792),\n",
      " ('prince', 0.5750998854637146),\n",
      " ('elizabeth', 0.546359658241272),\n",
      " ('daughter', 0.5399125814437866),\n",
      " ('kingdom', 0.5318052768707275),\n",
      " ('mother', 0.5168544054031372),\n",
      " ('crown', 0.5164472460746765)]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to answer the analogy -- man : king :: woman : x\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'king'], negative=['man']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv1gqPl5nQ4H"
   },
   "source": [
    "Let  m ,  k ,  w , and  x  denote the word vectors for man, king, woman, and the answer, respectively. Using only vectors  m ,  k ,  w , and the vector arithmetic operators  +  and    in your answer, what is the expression in which we are maximizing cosine similarity with  x ?\n",
    "\n",
    "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would man and woman lie in the coordinate plane relative to king and the answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zvj-YaOnTAY"
   },
   "source": [
    "The expression with which we want to maximise the cosine similarity of $x$ is $w + k - m$, so we want to maximise the similarity with woman and king and minimise it with man."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLyzhOOfnuql"
   },
   "source": [
    "### Question 3.5: Finding Analogies [code + written] (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5xFEsKVnzT0"
   },
   "source": [
    "Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
    "\n",
    "Note: You may have to try many analogies to find one that works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkrWfGGznRMH",
    "outputId": "f5515f38-b15c-4b93-cbd6-bee1695e7bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('water', 0.6592968702316284),\n",
      " ('supplies', 0.6487826108932495),\n",
      " ('potable', 0.5996021628379822),\n",
      " ('supply', 0.593157172203064),\n",
      " ('drink', 0.5844005346298218),\n",
      " ('sanitation', 0.5666312575340271),\n",
      " ('shortages', 0.5475372672080994),\n",
      " ('shortage', 0.5433778762817383),\n",
      " ('medicines', 0.5362359881401062),\n",
      " ('liquor', 0.5329169034957886)]\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# Write your implementation here.\n",
    "\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['drinking', 'food'], negative=['eating']))\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NygUqza7n8mn"
   },
   "source": [
    "The analogy is ``eating : food :: drinking : water``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMbSmc52n-Ni"
   },
   "source": [
    "### Question 3.6: Incorrect Analogy [code + written] (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKhHs5uooAaD"
   },
   "source": [
    "Find an example of analogy that does not hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the (incorrect) value of b according to the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayAfn_MPnzrF",
    "outputId": "10b17354-1b2e-4065-dbcf-88044a162968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rainbow', 0.42557501792907715),\n",
      " ('dark', 0.41235893964767456),\n",
      " ('water', 0.4081330895423889),\n",
      " ('clouds', 0.4053744673728943),\n",
      " ('ocean', 0.401736855506897),\n",
      " ('channel', 0.40050169825553894),\n",
      " ('sun', 0.3972149193286896),\n",
      " ('streams', 0.3970266580581665),\n",
      " ('darkness', 0.3943566679954529),\n",
      " ('light', 0.3930378556251526)]\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# Write your implementation here.\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['fish', 'sky'], negative=['bird']))\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsqq_EaXoDYl"
   },
   "source": [
    "The analogy is ``bird : sky :: fish : rainbow``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sBlWGAmoGCy"
   },
   "source": [
    "### Question 3.7: Guided Analysis of Bias in Word Vectors [written] (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_rVPQteoINq"
   },
   "source": [
    "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
    "\n",
    "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"worker\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"worker\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDlvsts2oBsp",
    "outputId": "06225d90-9903-4159-f03a-3d01d7fe10b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('employee', 0.6375863552093506),\n",
      " ('workers', 0.6068919897079468),\n",
      " ('nurse', 0.5837947726249695),\n",
      " ('pregnant', 0.5363885164260864),\n",
      " ('mother', 0.5321309566497803),\n",
      " ('employer', 0.5127025842666626),\n",
      " ('teacher', 0.5099576711654663),\n",
      " ('child', 0.5096741914749146),\n",
      " ('homemaker', 0.5019454956054688),\n",
      " ('nurses', 0.4970572590827942)]\n",
      "\n",
      "[('workers', 0.6113258004188538),\n",
      " ('employee', 0.5983108282089233),\n",
      " ('working', 0.5615328550338745),\n",
      " ('laborer', 0.5442320108413696),\n",
      " ('unemployed', 0.5368517637252808),\n",
      " ('job', 0.5278826951980591),\n",
      " ('work', 0.5223963260650635),\n",
      " ('mechanic', 0.5088937282562256),\n",
      " ('worked', 0.505452036857605),\n",
      " ('factory', 0.4940453767776489)]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be\n",
    "# most dissimilar from.\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'worker'], negative=['man']))\n",
    "print()\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'worker'], negative=['woman']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BtOxfydoLZb"
   },
   "source": [
    "We can see when \"man\" is positive and \"woman\" is negative we have words related to physical work such as \"laborer, mechanic, factory\", whereas when \"woman\" is positive and \"man\" is negative we have words related to medical or social work or housewives such as \"nurse, teacher, cihld, homemaker\". It reflects the stereotypes about men doing physical work and women staying at home or doing only \"caring\" work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMsfYJyxoNWT"
   },
   "source": [
    "###  Question 3.8: Independent Analysis of Bias in Word Vectors [code + written] (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h42ajQDcodeV"
   },
   "source": [
    "Use the most_similar function to find another case where some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9d5cbx3oJsf",
    "outputId": "809e2b90-d6b2-45f8-e523-6420e0c9c8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('william', 0.5237482190132141),\n",
      " ('james', 0.47425249218940735),\n",
      " ('davis', 0.46274280548095703),\n",
      " ('john', 0.45717188715934753),\n",
      " ('catholic', 0.4344415068626404),\n",
      " ('murder', 0.43297040462493896),\n",
      " ('tom', 0.4261571168899536),\n",
      " ('boston', 0.4239347577095032),\n",
      " ('henry', 0.42013466358184814),\n",
      " ('bill', 0.41822874546051025)]\n",
      "\n",
      "[('trafficking', 0.4890718162059784),\n",
      " ('crimes', 0.4821379482746124),\n",
      " ('terrorism', 0.46369433403015137),\n",
      " ('criminal', 0.4551544785499573),\n",
      " ('lawlessness', 0.4525734782218933),\n",
      " ('smuggling', 0.45193836092948914),\n",
      " ('corruption', 0.4442726671695709),\n",
      " ('terrorist', 0.4420980215072632),\n",
      " ('combating', 0.4362676739692688),\n",
      " ('somali', 0.43594610691070557)]\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# Write your implementation here.\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['thomas', 'crime'], negative=['mohamed']))\n",
    "print()\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['mohamed', 'crime'], negative=['thomas']))\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDBxYCeEolk5"
   },
   "source": [
    "\n",
    "The first list of words are related positively to \"thomas, crime\" and negatively to \"mohamed\", and on the second list of words \"thomas\" is negative and \"mohamed, crime\" is positive.\n",
    "We can see the first list has mostly generic other occidental names (\"william\", \"james\", \"john\"), while the second list contains words related to terrorism and crime, such as (\"trafficking\", \"terrorism\", \"criminal\"). This show a bias reflecting the stereotype of arabic names being more related to crime than occidental names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNaetQ4donRi"
   },
   "source": [
    "### Question 3.9: Thinking About Bias [written] (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mktU3tdqtzp"
   },
   "source": [
    "Give one explanation of how bias gets into the word vectors. What is an experiment that you could do to test for or to measure this source of bias?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SAsM_bncFH0"
   },
   "source": [
    "This bias can come from the fact the dataset contains these stereotypes. Thus it is easier for the model to exploit the stereotypes to maximise its similarities when learning the embedding. To test and measure this we could try to modify the corpus and see how these biases evolve to see how strong they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrXQ2d7OsmLl"
   },
   "source": [
    "# Part 4. Prediction-based sentence vectors (13 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOP9j0mV2rvU"
   },
   "source": [
    "Sentence embeddings are a more powerful representation than word embeddings. They allow you to have out-of-the-box sentence representation of sequences of tokens which is closer to what you would have in reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ3pVRQ8wE4P"
   },
   "source": [
    "### Question 4.1: How would you represent a sentence with Glove? What are the limits of your proposed implementation? [written] (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1w30iYj0YJn"
   },
   "source": [
    "We could represent a sentence by computing the average of the embeddings of each word in the sentence. However this would give an equal weight to each word in the sentence even though some words carry more meaning in the sentence. This would also fail to relate link between specific words or exploit particular n-grams with high meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2n3vp8g3AEe"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9F_tbMr3CZT"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBTJnO606Tpc"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnidR9Gg2697"
   },
   "outputs": [],
   "source": [
    "def load_embedding_model():\n",
    "    \"\"\" Load SentenceBERT Vectors\n",
    "        Return:\n",
    "            embedder: sentence embedder \n",
    "    \"\"\"\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    return embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qzL9oBS4Zoc"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "embedder = load_embedding_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKkFzRHe6bEm"
   },
   "source": [
    "Inspired by the above, choose the appropriate way to plot the below clusters. Do they make sense to you? What would you improve to get a meaningful plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-o3T8Wz-Feb"
   },
   "source": [
    "### Question 4.2. Evaluate clustering quality of SentenceBERT. What makes it good at clustering sentences? Which method of the two below would you go for? [written] (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqHOmWtqyNo3",
    "outputId": "ef8149e6-32b9-454c-d433-324ef8c7c01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  1\n",
      "['The girl is carrying a baby.', 'The baby is carried by the woman']\n",
      "\n",
      "Cluster  2\n",
      "['A cheetah is running behind its prey.', 'A cheetah chases prey on across a field.']\n",
      "\n",
      "Cluster  3\n",
      "['A man is eating food.', 'A man is eating a piece of bread.', 'A man is eating pasta.']\n",
      "\n",
      "Cluster  4\n",
      "['A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.']\n",
      "\n",
      "Cluster  5\n",
      "['A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'A man is eating pasta.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'The baby is carried by the woman',\n",
    "          'A man is riding a horse.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.',\n",
    "          'A cheetah is running behind its prey.',\n",
    "          'A cheetah chases prey on across a field.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Perform kmean clustering\n",
    "num_clusters = 5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4wF5uTy50Nt",
    "outputId": "f56fcdfe-c61f-4669-d3b9-0b91a1ed9260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  1\n",
      "['A man is eating food.', 'A man is eating a piece of bread.', 'A man is eating pasta.']\n",
      "\n",
      "Cluster  5\n",
      "['The girl is carrying a baby.', 'The baby is carried by the woman']\n",
      "\n",
      "Cluster  2\n",
      "['A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.']\n",
      "\n",
      "Cluster  3\n",
      "['A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.']\n",
      "\n",
      "Cluster  4\n",
      "['A cheetah is running behind its prey.', 'A cheetah chases prey on across a field.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'A man is eating pasta.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'The baby is carried by the woman',\n",
    "          'A man is riding a horse.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.',\n",
    "          'A cheetah is running behind its prey.',\n",
    "          'A cheetah chases prey on across a field.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Normalize the embeddings to unit length\n",
    "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Perform kmean clustering\n",
    "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=1.5) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = {}\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_sentences:\n",
    "        clustered_sentences[cluster_id] = []\n",
    "\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "for i, cluster in clustered_sentences.items():\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlGPpj5kyyp_"
   },
   "source": [
    "The clustering quality on this sample is very good as the most similar sentences have been detected. This is because the sentences are embedded as a whole leading to efficient semantic text similarity using cosine similarity. The method we would choose is agglomerative clustering, as it seems to be better when the number of clusters is not known in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44mDLKmVyOUu"
   },
   "source": [
    "### Question 4.3: SentenceBERT Plot Analysis [written] (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_ykELvWt7ZX"
   },
   "source": [
    "Plot the above corpus with your favorite method in a 2-dimensional space. Comment on the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "0Jpm3C1K5RnK",
    "outputId": "769e1c1b-fb48-4ac3-f9a7-77ab31f57423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 11 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArQAAAEvCAYAAAC0d1LHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVhV5d4+8PsBEUFUHEucAAOUcTMGIiCO+GooKscxRRKHV7PsdxzSHF86WViKnU5mpWiWcw6ZFVmQ4hCggSPOmILHnEBQiOn7+wNZBwQcksJ9vD/XxVV77Wet51lrbepm7WdQIgIiIiIiIn1lUNsNICIiIiJ6HAy0RERERKTXGGiJiIiISK8x0BIRERGRXmOgJSIiIiK9xkBLRERERHqtTm03oDrNmjUTS0vL2m4GERER0QMdPHjwmog0r+12PK2e2EBraWmJ5OTk2m4GERER0QMppS7UdhueZuxyQERERER6jYGWiIiIiPQaAy0RERER6TUGWiKiJ8zWrVuhlEJaWtoj7RcWFoZNmzbVSBv+8Y9/PFQ5MzOzB5bZvn07Fi5c+LhNqhH/8z//g6ysrMc+Tnx8PPr27ftI+1haWuLatWuVtv+R61PdvZ4zZw527doFAFiyZAnu3LnzSMcl0lcMtERET5i1a9eic+fOWLt2ba214WED7cMIDg7GjBkzHnm/oqKiGmtDmZ07d8Lc3LzGj/s4/uj1qcqCBQvQvXt3AH9OoP0z7glRTWCgJSJ6guTm5iIhIQGffvop1q1bV2251atXw9nZGS4uLnjxxRe17bt370anTp1gbW1d4QleVFQUPD094ezsjLlz52rb16xZAy8vL+h0OowbNw7FxcWYMWMG8vLyoNPpMHz4cABA//794e7uDgcHByxfvrxCW2bNmgUXFxd4e3vjypUrldoaExODSZMmAQA2btwIR0dHuLi4wN/fv1LZ+Ph4+Pn5ITg4GPb29khPT4ejo6P2/qJFizBv3jwAQJcuXTB9+nR4eXnB1tYWe/bs0eobMGAAgoKCYGNjg2nTpmn7lz0lTU9PR8eOHREREQEHBwf07NkTeXl5AICkpCQ4OztDp9Nh6tSpFeov79atW+jTpw/s7Owwfvx4lJSUAABiY2Ph4+MDNzc3hIaGIjc3V9vn/fffh5ubG5ycnLQn8OWvT1hYGCZPnlzpHooIJk2aBDs7O3Tv3h2//fZblW0qe3K7dOlSZGZmIjAwEIGBgSguLkZYWBgcHR3h5OSExYsXV7nv+PHj4eHhAVtbW+zYsUNrX3BwMLp27Ypu3brh9u3bCA8Ph5eXF1xdXbFt2zYAgL+/P1JSUrTjde7cGampqVW2k6imMdASET0htm7digYNGsDb2xu2trZo2rQpDh48WKncsWPHEBkZiR9//BGpqakoKirSgs/ly5eRkJCAHTt2aE/9YmNjcfr0aSQmJiIlJQUHDx7E7t27ceLECaxfvx579+5FSkoKDA0NMWTIECxcuBAmJiZISUnB559/DgBYsWIFDh48iOTkZCxdulTranD79m14e3sjNTUV/v7++Pjjj+97jgsWLMD58+eRmpqK7du3V1nm0KFDiI6OxqlTpx54zYqKipCYmIglS5Zg/vz52vaUlBSsX78eR44cwfr163Hx4sVK+54+fRoTJ07EsWPHYG5ujs2bNwMARo8ejY8++ki7JtVJTEzE+++/j+PHj+Ps2bP48ssvce3aNURGRmLXrl04dOgQPDw88N5772n7NGvWDIcOHcKECROwaNGiKo9b1T3csmULTp48iePHj2P16tXYt2/ffa/L5MmTYWFhgbi4OMTFxSElJQUZGRk4evQojhw5gtGjR1e5X3p6OhITE/H1119j/PjxyM/PB1B6TzZt2oSffvoJb775Jrp27YrExETExcVh6tSpSE9PR0ZGBnr27Ik9e/YgICAAubm5cHFxqbaN1XXBmDdvXrXXhqg6T+w8tERET4utv2Qg6ruTSFn1HuqYNMC10gyBIUOGYO3atXB3d69Q/scff0RoaCiaNWsGADA2Ntbe69+/PwwMDGBvb689LY2NjUVsbCxcXV0BlD4FPn36NA4fPoyDBw/C09MTAJCXl4fz589X2calS5diy5YtAICLFy9qTyPr1q2r9SV1d3fH999/f99z9fX1xYkTJ/Dxxx9jwIABVZbx8vKClZXVfY9TpuwY7u7uSE9P17Z369YNjRo1AgDY29vjwoULaNOmTYV9raysoNPpKuyflZWFnJwc7ZoMGzZMe1JZVTutra0BAEOHDkVCQgLq1auH48ePw9fXFwBQUFAAHx+fKtv75ZdfVnncqu7h7t27MXToUBgaGsLCwgJdu3atct+y+3Iva2trnDt3Di+//DL69OmDnj17Vlnub3/7GwwMDGBjYwNra2vtKXKPHj3QpEkTAKWfp+3bt2uhMz8/H5s3b4afnx8SEhLg7e0NHx8ftG7duso6iP4MfEJLRFSLtv6Sgde/PIKLv91A/sWjKCrIx+5vt6GFRRtERUVhw4YNEBGt/OrVq7Fw4UJ88sknlboa7Ny5E6+99lqFr6mjoqKwZs0aFBUVoV+/fkhJScGZM2dgbGyMqKgoFBcX4/nnn8fBgwcREhKC4uJi6HQ67clc//79YWtri3feeQcRERFITU2Fq6srRASzZs1CUVERfHx8cOXKFRgaGlboY5mbm4vRo0fjjTfewLp167B582YsW7YMdevWxapVq9CyZUt4eHhooe2rr77ChAkTcOjQIXTv3h1XrlxBnTp1kJOTA51OB51Oh3fffRe///47gNJgHRERAWdnZyxatAhFRUW4ffs2Fi9ejC1btsDR0RHr16+v1K5+/fph/vz5uHTpEhwdHZGYmAhDQ0Ps2rUL48aNw7///W+8+OKLuHr1Kl577TWcPXsWnp6e2Lt3L0pKSmBjY4OsrCwopVBSUoLnnnsOOTk5UEpBRNCjRw/8+OOPsLS0RJ06dXDs2DEcPnwYABAdHY3w8HD87//+L/bu3YulS5dW+kwYGxtjwoQJ8PDwwO3btyt0EUlKSkKnTp3www8/YMaMGcjJyanQJSA2NhY5OTno378/MjMzERQUhMOHD6Nx48b44IMPsGPHDgwePBjNmzdHTk4OLl++DH9/f+h0Omzbtg2nT5+u0BalFLZt24adO3fC0dERY8eORUlJCTZv3oyUlBSkpKRg+/btiI6Oxtdff42srCxs2LAB7777LoKCggBU3a3lXm+++SZsbW3RuXNnnDx58mF+dYgqYKAlIqpFUd+dRF5hMe6cPoA65s/CzLEbjJ+1QcuBs3Dx4kVYWVlpfUPLuhqsX78ejRo10oLO77//jsuXL6N3796YMWOG9jV1UVERTp8+jVWrVsHCwgI///wzdu/ejfj4eKxevRrbt29Hw4YNUVBQgM8//xzTpk1DvXr1kJKSggYNGqCwsBArVqxAVFQUunTpgmXLlmH//v04cOAA8vPz4e3tDRMTk2q7Gvzf//0fGjVqhMjISAwZMgRdu3bF2bNnkZeXh+nTp8PFxQWOjo7avp07d8a//vUv+Pn5YciQIXjnnXfwzDPP4PLly/jHP/6Bn3/+Ga1bt4aRkRFiY2ORl5eHVatWISUlBampqcjPz8e3334Lc3NzDBkyBEePHtVC1b3y8vLQvn17/Otf/0J4eLi2/cyZM2jfvj1effVVvPLKK2jZsiXat2+PzZs3Y8yYMTAwMMCIESOwa9cuJCYmYs2aNXB2dsbOnTvRuXNneHt7Y+/evXj11Vfh6uqK/fv3Y8KECRg5cqRWR1pamtaXdv78+VUOtHrzzTeRnJwMExMT/PTTT2jbti3Wrl2LwYMHY/bs2TAwMMCcOXNgYmIC4D9dAoKCgrBhwwa4urrCzs4OU6ZMwciRI3Ht2jVER0djzZo12Lt3LywsLGBiYoIvvvgCvXr1QkpKCl544QUcPHgQJSUlOHv2LM6dOwc7Ozt069YNoaGhOHr0qHbd3n//fe0PLRHBggULMHjwYHz33XeYOnUq6tatC3Nz8yq7tZR1Yylz8OBBrFu3DikpKdi5cyeSkpIe7peHqBx2OSAiqkWZWaUDke6c2A0pyIOprQ8Km7VF+s+xAMZj4MCBWLt2Lfz9/bWuBp07d8asWbPQv39/GBoa4vbt25g/fz6+//57tGnTRnviWVxcjNjYWCQmJuLq1atITU3FkSNHULduXdy5cwejRo1CYWEh1q5di507dyI6OloLKWPHjoWzszPq1KkDpRTS09Nx+/ZtTJ8+Hd7e3ti3b1+lrgYdOnSocG67du3CunXrsHfvXgBA48aN8dJLL0EphRkzZqB79+7w8fHRppm6dOkSpk2bhpMnT+L06dOwsrKCkZERevXqhQEDBqBVq1Zwc3ODgYEBYmNjcePGDQwfPhympqbIzs5GYWEhnJyccOzYMeTk5GDPnj3w8/Or8roHBwfj6NGj8Pf3x61bt7QBYcHBwQgKCkJERAROnDgBc3Nz3LlzB8HBwbh16xZyc3MRHh6Obt26wdPTEzNmzIBSCi+88AJCQkJgYGCAmJgY9O3bF23btsXmzZsRGRmJ69evQykFAOjTpw/q1q0LIyMjtGjRArdu3arUvg0bNmD58uXIy8vDsWPHMG7cODRr1gwJCQl477334OPjA1NTU9SpU/q/8fJdAtLS0vDBBx+gSZMmWLBgAS5cuICTJ08iNTUVPXv2hLm5ORYuXIg6derA09MT4eHhKCwsRFZWFqytreHl5YVbt25h2bJlqFevHtLS0rBx40b89NNPuHHjBsaPH49Lly7B2dkZJSUlsLKywqBBg7TPQsOGDbWnsK+99hp+/vnnCt1aWrRoUeFc9+zZg5CQEJiammr3gOiRicgT+ePu7i5ERP/Nthy6JNYzvpbWk9eKqmMshg2bi2HDFmLYoJnUbdRCSkpKKpRfunSpzJw5s9JxRo0aJRs3btRe169fX0REXnvtNVm2bFml8kuXLpUZM2ZU2aayfUVE4uLixNfXV27fvi0iIgEBARIXF1ep3MaNG2XUqFGVjuXm5ianTp26bx3l9w0ICJBt27ZpdQcEBGjlDh8+LAsXLpS2bdvKiRMnqj03EZHr16/LZ599Jv7+/jJ//vxK7wcEBMiPP/6ovW7Tpo1kZWXJ3LlzJSoqSnJyckREpGnTprJgwQKZPHlypWMEBQXJDz/8IFZWVlJUVFTpfZ1OJ2fPntVet27dWrKzs7U6yjg4OMj58+cr7Hvu3Dlp37693LhxQ0RK7+/KlSvl8OHD0qlTp0p1rVy5UiZOnPjAukUqX0cRkYyMDFm+fLk0btxYJk2aVOHYeXl50qJFC/n1119FRGTu3Lkyd+7catuQkZEhNjY20q5dO7l69ep9P2tlZRYvXiyzZ8/Wtk+ZMqXCNdIXAJLlCchPT+sPuxwQEdWCsr6zxSK4c3Iv6jsEovWElWg9YQVsXvkMz7X/T1eDMl27dsXGjRtx/fp1AMCNGzfuW0evXr2wYsUKbdqojIwM/Pbbb+jWrRs2bdqkTf1048YNXLhwAQBgZGSEwsJCAEB2djYaN24MU1NTpKWl4cCBA490jj169MAHH3ygvb558+Z9y2dnZ6NVq1YAgFWrVmnbz549CycnJ0yfPh2enp5IS0ur9twyMzNhamqKESNGYOrUqTh06FCVda1fvx4AkJCQgEaNGmkDyADg66+/hk6nQ1FREb744gu88cYbAFBhSqoxY8ZgxIgRCA0NrXImBD8/P+2r9fj4eDRr1gwNGza87/mXuXXrFurXr49GjRrhypUr+OabbwAAdnZ2uHz5svaVfE5OTpXdFaqru6rreOHCBTzzzDOIiIiAjY0Nzp07V+FYZX2pmzVrhtzc3Psu3JGWlobnn38eb775prbtfp+1Mv7+/ti6dSvy8vKQk5ODr7766qGuE1F57HJARFQLyvrOAsDtEz+h0fOlX9kaKoW3Bjjh1+bDtK4GZRwcHDBr1iwEBATA0NAQrq6uiImJqbaOnj174sSJE9ooezMzM6xZswb29vaIjIxEz549UVJSAiMjI3zwwQdo166d1tXAzc0NK1aswLJly9CxY0fY2dnB29v7kc7xjTfewMSJE+Ho6AhDQ0PMnTu32pkNgNLpmkJDQ9G4cWN07dpVm3FhyZIliIuLg4GBARwcHNC7d28YGxtXeW5nzpzB1KlTYWBgACMjI3z44YdV1lWvXj24urpq/YTLGzx4MAYPHoxr165h4sSJ6NatG4qKiuDv749ly5YBKP1afPTo0dVOfzVv3jyEh4fD2dkZpqamFQL6g7i4uMDV1RUdOnRAmzZttBkT6tati/Xr1+Pll19GXl4eTExMtO4aD1N3Vddx3bp1iIqKgpGREczMzPDPf/6zwrHMzc0REREBR0dHPPvss1rXgap06NBBa8/UqVMB4L6ftTJubm4YPHgwXFxc0KJFiwp1lF3v8ePHP/T1o6eTKn1K/uTx8PCQ5OTk2m4GEdGfwmrG16jqv74KwPmFff7q5jxVunTpgkWLFsHDw+MPHyM5ORlTpkyp9BSdnl5KqYMi8sc/VPRY2OWAiKgWWJibPNJ2enIsXLgQAwcOxFtvvVXbTSGiu/iEloioFpT1oS3rdgAAJkaGeGuAE/q7tqrFlhHRH8EntLWLfWiJiGpBWWiN+u4kMrPyYGFugqm97BhmiYj+AAZaIqJa0t+1FQMsEVENYB9aIiIiItJrDLREREREpNdqJNAqpYKUUieVUmeUUjOqKfM3pdRxpdQxpdQXNVEvEREREdFj96FVShkC+ABADwCXACQppbaLyPFyZWwAvA7AV0RuKqVaVH00IiIiIqJHUxNPaL0AnBGRcyJSAGAdgH73lIkA8IGI3AQAEfmtBuolIiIiIqqRQNsKwMVyry/d3VaeLQBbpdRepdQBpVRQDdRLRERERPSXTdtVB4ANgC4AWgPYrZRyEpGs8oWUUmMBjAWAtm3b/kVNIyIiIiJ9VhNPaDMAtCn3uvXdbeVdArBdRApF5DyAUygNuBWIyHIR8RARj+bNm9dA04iIiIjov11NBNokADZKKSulVF0AQwBsv6fMVpQ+nYVSqhlKuyCcq4G6iYiIiOgp99iBVkSKAEwC8B2AEwA2iMgxpdQCpVTw3WLfAbiulDoOIA7AVBG5/rh1ExEREREpEantNlTJw8NDkpOTa7sZRERERA+klDooIh613Y6nFVcKIyIiIiK9xkBLRERERHqNgZaIiIiI9BoDLRERERHpNQZaIiIiItJrDLREREREpNcYaImIiIhIrzHQEhEREZFee+oD7fXr16HT6aDT6fDss8+iVatW0Ol0MDc3h729/Z9SZ6dOnap9z8zM7JH3qQ2ZmZkYNGjQX1ZffHw8+vbt+0j7WFpa4tq1a39Si4iIiOhJ8dQH2qZNmyIlJQUpKSkYP348pkyZor02MPhzLs++ffsqbSsqKnrkfWravW24X5ssLCywadOmP7tJRERERA/01Afa+ykuLkZERAQcHBzQs2dP5OXlAQDOnj2LoKAguLu7w8/PD2lpaZX2vXr1Knr06AEHBweMGTMG7dq1054Wlj2FjY+Ph5+fH4KDgx/4NLhsn8uXL8Pf3x86nQ6Ojo7Ys2dPpbJJSUno1KkTXFxc4OXlhZycHKSnp8PPzw9ubm5wc3PTAvK9bbj39Zw5c7BkyRLt2LNmzUJ0dDTS09Ph6OgIAIiJicGAAQMQFBQEGxsbTJs2TSv/6aefwtbWFl5eXoiIiMCkSZMqtTcxMRE+Pj5wdXVFp06dcPLkySqvwa1bt9CnTx/Y2dlh/PjxKCkpAQBMmDABHh4ecHBwwNy5cyvs884778DJyQleXl44c+YMcnJyYGVlhcLCQu2Y5V8TERGRHhKRJ/LH3d1d/mpz586VqKgoERE5f/68GBoayi+//CIiIqGhofLZZ5+JiEjXrl3l1KlTIiJy4MABCQwMrHSsiRMnyj/+8Q8REfnmm28EgFy9elVEROrXry8iInFxcWJqairnzp3T9it7715l2xctWiSRkZEiIlJUVCS3bt2qUO73338XKysrSUxMFBGR7OxsKSwslNu3b0teXp6IiJw6dUrKru+9bbj39fnz58XV1VVERIqLi8Xa2lquXbsm58+fFwcHBxERWblypVhZWUlWVpbk5eVJ27Zt5ddff5WMjAxp166dXL9+XQoKCqRz584yceLESudW1kYRke+//14GDBhQqUxcXJwYGxvL2bNnpaioSLp37y4bN24UEZHr169r1yMgIEBSU1NFRKRdu3batVq1apX06dNHRETCwsJky5YtIiLy0UcfyWuvvVblNSciInpYAJLlCchPT+tPndoO1E8yKysr6HQ6AIC7uzvS09ORm5uLffv2ITQ0VCv3+++/V9o3ISEBW7ZsAQAEBQWhcePGVdbh5eUFKyurh26Tp6cnwsPDUVhYiP79+2vtK3Py5Em0bNkSnp6eAICGDRsCAG7fvo1JkyYhJSUFhoaGOHXqVLVtKP/a0tISTZs2xS+//IIrV67A1dUVTZs2RU5OToV6u3XrhkaNGgEA7O3tceHCBVy7dg0BAQFo0qQJACA0NLRCvWWys7MxatQonD59Gkqpap+Wenl5wdraGgAwdOhQJCQkYNCgQdiwYQOWL1+OoqIiXL58GcePH4ezs7NWruyfU6ZMAQCMGTMG77zzDvr374+VK1fi448/fuB1JyIioifXUxtot/6SgajvTiIzKw8W5iaY2suuUhlDQ0MtMJ49exZKKWzYsAG///47CgoKcPz48T9Ud0FBARYtWgQPDw/Ur1//geXT09Nx584dAIC/vz92796Nr7/+GmFhYXjttdcwcuTI++4/ZswYGBsb45lnnkFqaipKSkpQr1497f1723Dv6zFjxiAmJgb//ve/ER4eXmUdxsbG2r8bGhpq/W/37duH48eP37dLxezZsxEYGIgtW7Zg3bp1Vdbx7bff4uzZsxW2KaVw/vx5LFq0CElJSWjcuDHCwsKQn59foUxWVhY+++wzKKUAAIWFhYiLi0N8fDyKi4u1rhNERESkn57KPrRbf8nA618eQUZWHgRARlYeXv/yCNIu36pQrk6dOtoAMR8fH3h7e+Pw4cPQ6XTIzc0FUNplIzU1tVIdvr6+2LBhAwAgNjYWN2/erJG2X7hwAc888wwiIiIwZswYHDp0qML7dnZ2uHz5MpKSkgAAOTk5WLZsGerWrYuWLVvCwMAAn332GYqLix+6zpCQEHz77bdISkpCr169qi137zHd3NxQWFiIli1boqioCJs3b65yv+zsbLRq1QpAaXCtzpUrV3D+/HmUlJRg/fr16Ny5M27duoX69eujUaNGuHLlCr755psK+6xfvx5ZWVl4++234ePjo21v3bo1hg0bhtGjRz/w/ImIiOjJ9lQG2qjvTiKvsGL4yissxt6z1x9q/+joaNy4cQNNmzZFvXr1MHDgwEoDxhISEvDWW2/BxsYGGzduxLPPPosGDRpox0hNTcXEiRMRFxenfeWdm5uLvLw8uLm5wcnJCdu2batQ7/Dhw+Hj44MmTZrAxcUFH330UYWnxN9//z0GDx6M9evX4+WXX4aLiwt69OiBwMBA+Pn5ISYmBk2aNMG0adOglMLixYsrnduNGzeQnJwMFxcXuLi4YN++fahbty4KCgpw584dODs7Y/ny5Vp5MzMzrFu3DuvWrcP+/fthZmaG48eP46WXXsKvv/4KY2NjODs7w9fXF3Xr1sXWrVvh5uaG0NBQ7Y8Cf39/DB06FKampjh27Fi1171Ro0bw8PBAvXr1cP36dYSEhGDz5s0wNjZGhw4dMGzYMJibmyM2Nlbb5+bNm9DpdMjMzMSZM2cwdepUAIC5uTmuXLmCxYsXY/jw4ejduzcyMzNx8OBBBAQEwN3dHb169cLly5crtKG4uBhWVlYQEWRlZcHQ0BC7d+/WzuP06dO4ceMG+vfvD2dnZ+2PIACYN28eRo0aBT8/P7Rr1w5ffvklpk2bBicnJwQFBWldLRYsWABPT084Ojpi7NixKO2aBXTp0gXTp0+Hl5cXbG1tqxwQSERE9FSq7U681f38mYPCLKfvkHZV/FhO31HtPo86YCw/P18SEhIkMDBQ9u3bJy4uLhWO5ezsLHfu3JGrV69K69atJSMjQwoLCyU7O1tERK5evSrt27eXkpISOX/+vACQhIQEEREZPXq0REVFSUlJidjZ2clvv/0mIiJDhw6V7du3V2p7QECAJCUlSXJysnTv3l3bfvPmzUpl//a3v8nixYtFpHSQVVZWlhQXF4uDg4OcOnVK7ty5Iw4ODnLt2jUREQEg69ev1/a/93Xnzp0lKSlJLl++LE2aNJEvvvhCREQWLlwo8+fPl7y8PGndurWcOnVKSkpKJDQ0VBu8Vd7KlSvl2WeflWvXrmltSEpKqnbQWnnlB7CJlA4wMzExkZCQECkuLhZvb2/Zs2ePFBQUiI+Pj3Y9161bJ6NHj67Ull69esnRo0flq6++Eg8PD4mMjJT8/HyxtLQUEZFJkybJvHnzRETkhx9+0O793LlzxdfXVwoKCiQlJUVMTExk586dIiLSv39/baBa2SA3EZERI0Zo9zQgIEAbwPb1119Lt27dKrWNiIhqBzgorFZ/nsontBbmJo+0vSoPGjCm0+nQvXt37Nu3D5MnT6408Khfv34wMTFBs2bNEBgYiMTERIgIZs6cCWdnZ3Tv3h0ZGRm4cuUKAKBNmzbw9fUFAIwYMQIJCQlQSuHFF1/EmjVrkJWVhf3796N3797Vttna2hrnzp3Dyy+/jG+//VYbMFbejz/+iAkTJgAo7QubkZGB5557Dg0aNMCgQYPg7e2Nixcv4vTp01qZgQMHavvf+zo9PR3Dhg2Dh4cH7ty5g7fffhs6nQ6rVq3ChQsXkJaWBisrK9jY2EAphREjRlTb/h49eqBp06YwMTHBgAEDkJCQUGHQWmxsrDZo7X6io6MBAAsXLoSBgQF0Oh3S09Nx8uRJHD16FD169IBOp0NkZCQuXbpUaX8/Pz/s3r0bu3fvxuuvv46EhAQkJSVpA/ESEhLw4osvAgC6du2K69ev49at0u4svXv3hpGREZycnFBcXIygoCAAgJOTE9LT0wEAcQcY4TwAACAASURBVHFxeP755+Hk5IQff/yxwlPrAQMGAPjPZ46IiIie0kFhU3vZ4fUvj1TodmBiZKgNDHuYAWP3DoLKy8tDSUkJzM3NkZKS8sA2lA1QKv/6888/x9WrV3Hw4EEYGRnB0tJSG+BUVXkAGD16NF544QXUq1cPoaGhqFOn+lvauHFjpKam4rvvvsOyZcuwYcMGrFix4r7ttLe3x4oVK/DGG29g//79MDU1RZcuXbR21atXD4aGhlr5e1+3b98eixYtwuXLl/HFF19g7dq1FY7/MNfq3nO+9/XDDFor75VXXkFhYSFsbW0B/GcQm4jAwcEB+/fvv+/+/v7++PDDD5GZmYkFCxYgKipKm7/3Qco+NwYGBjAyMtLOwcDAAEVFRcjPz8f//u//Ijk5GW3atMG8efMqDHIr27/8wDsiIqKn3VP5hLa/ayu8NcAJrcxNoAC0MjfBWwOc0N+11UMPGKtKw4YNYWVlhY0bNwKofsAYAGzbtg35+fm4fv064uPj4enpiezsbLRo0QJGRkaIi4vDhQsXtPK//vqrFrS++OILdO7cGUDpil0WFhaIjIx84ACna9euoaSkBAMHDkRkZGSlAWVA6fRbH374IYDS/qLZ2dnIzs5G48aNYWpqirS0NBw4cOCB1+Je3t7e2Lt3L86cOQOgdBqxU6dOoUOHDkhPT9dmMLg38Jb3/fff48aNG8jLy8PWrVu1J9YPGrTWoEGDStOMVcXOzg5Xr17VrnNhYWGVfXq9vLywb98+GBgYoF69etDpdPjoo4/g7+8PoPQJ7ueffw6gdOGKZs2aVfk0vCpl4bVZs2bIzc3lamxEREQP4al8QguUhtr+rq0qbb/fgDEPG4sHHvfzzz/HhAkTEBkZicLCQgwZMgQuLi6Vyjk7OyMwMBDXrl3D7NmzYWFhgeHDh+OFF16Ak5MTPDw80KFDB628nZ0dPvjgA4SHh8Pe3l7rFgCUDha7evUqOnbseN+2ZWRkYPTo0doKW2+99ValMtHR0Rg7diw+/fRTGBoa4sMPP0RQUBCWLVuGjh07ws7ODt7e3g+8Dvdq3rw5YmJiMHToUG3e3sjISNja2mL58uXo06cPTE1N4efnV2349PLywsCBA3Hp0iWMGDECHh4eAIC6desiMDAQ5ubmFZ4Ol2natCl8fX3h6OiI3r17o0+fPlUev27duti0aRMmT56M7OxsFBUV4dVXX4WDg0OFcsbGxmjTpo12Hfz8/LB27Vo4OTkBKB38FR4eDmdnZ5iammLVqlUPfZ3Mzc0REREBR0dHPPvss1o3BiIiIqqeKu3H/OTx8PCQ5OTkv7xeqxlfo6orogCcX1h1EKptkyZNgqurK1566aXabkqtKCkpgZubGzZu3AgbG5vabg7Vsq1btyIkJAQnTpyo8Efhny09PR19+/bF0aNHa+yYy5Ytg6mp6QPnmn4QMzMzbVaRR5GZmYnJkyf/Kd8UWFpaIjk5Gc2aNavxYxPVBqXUQRHxqO12PK2eyi4H91MTA8b+Su7u7jh8+PB9B1P9Nzt+/Diee+45dOvWjWH2Kffmm2/CwcEBYWFhqF+/PqKiomq7SY9s+/btWLhwofZ6/Pjxjx1mH4eFhQU2bdqE5ORkTJ48GQAQExODSZMmASj9NmLRokU1Vp+IaN8gVScmJgaZmZk1VufDWLZsGVavXv3YxzEzM/tD+2VmZmLQoEGPXf+fZcmSJdriPw9rz549cHBwgE6n06a9rEpNf8bovxcD7T2m9rKDiVHFr63LDxh70hw8eBC7d++uMEjtaWJvb49z587h3Xffre2mUC3av38/duzYgd27d6N+/frYtWsX4uPjqyybnp6ODh06ICwsDLa2thg+fDh27doFX19f2NjYIDExEQDuO59weHg4unTpAmtrayxdurRSHefOnYOrqyuSkpK0uand3d3h5+eHtLQ05OTkwMrKSpt7+NatW7CyskLv3r0xY8YM7Tjl/2e+dOlS2Nvbw9nZGUOGDKlUZ0xMDPr164cuXbrAxsYG8+fPr1QmNzcX3bp1qzTX9Zw5c7BkyRKt3KxZsxAdHY309HQ4ODjAw8MDbm5uGDBgAN59912sWbMG06ZN08p/+umnsLW1hZeXFyIiIrTAW97169fRs2dPODg4YMyYMSj7djA9PR12dnYYOXIkHB0dcfHixQrBb9OmTQgLCwMAhIWFYebMmejZsyesra0RHx+P8PBwdOzYUStTXFyMsLAwODo6wsnJqcr5th/Vk/KHxZPqjwTazz//HK+//jpSUlJgYvLoD4w4KJYqqe15w6r7+TPnoX2QLYcuSae3fhDL6Tuk01s/yJZDl2qtLUT0YJs3b5a+ffvKmjVrJDw8XEREfHx8JDk5WXbt2iU6nU4cHR1l9OjRkpaWJoaGhmJhYSHTp08XExMTadq0qSQnJ4tOpxNTU1P58MMPtfmE33nnHbGzs5N69erJnDlzZO7cueLj4yNvv/22dOjQQQwNDWXRokVy/vx5sbGxEWtra2nSpIlYW1tLjx49JCAgQE6dOiVnzpwRb29vMTMzk86dO1eYe/ijjz6S1157TVauXCkTJ04UEZFRo0aJl5eXtGvXTqysrMTc3Fzy8/NFpOIc0v369RM3NzexsLCQhg0bVpqrWUTE2NhY7OzsxNXVVcaNGyd9+vSRq1eviqWlpfTr10/s7OzE1NRUUlNTpbi4WMzNzSU0NFTc3d2lYcOGEhcXJy4uLmJlZSUffPCBjBs3Ttq2bSuvvvqqzJ49W9q1ayeLFy8Wd3d3MTU1FWtra7l9+3aFe/Tyyy/LzJkzJSwsTNq1aycAZMWKFdo829bW1uLg4CDTpk2T+vXrS1FRkYwaNUratGkj5ubm8t5770lAQIDUqVNHbG1txdLSUszMzMTCwkKuXLkibm5usmbNGnFzc5Pu3bvL3LlzZeTIkeLt7S1t27aVzZs3y9SpU8XR0VF69eolBQUFIiKSnJws/v7+4ubmJj179pTMzMxKn6/y85BHR0dLx44dxcnJSQYPHlyp7MqVKyU4OFgCAgLkueee0+akFhGpX7++iIjk5ORI165dxdXVVRwdHWXr1q0iIjJ79mxtHnARkZkzZ8qSJUsqzKW9cuVKCQkJkV69eslzzz0nU6dO1cp/8sknYmNjI56enjJmzBjts1Tezz//LN7e3qLT6cTHx0fS0tIqlcnMzBQ/Pz9xcXERBwcH2b17t4iIfPfdd+Lt7S2urq4yaNAgycnJkejoaDEyMhJHR0fp0qVLpWPd+/uXn58vH3/8sTRu3FgsLS1l2LBhlfaJjIwUGxsb8fX1lSFDhmjXPiAgQF555RVxd3eXRYsWyahRo2Tjxo2Vrm9cXJz4+/tLcHCwWFlZyfTp02XNmjXi6ekpjo6OcubMGRER2bBhgzg4OIizs7P4+flVasejAuehrdWfWm9AdT+1GWiJSL/k5OSIi4uL1K9fX/r27Svx8fESHR0tr7zyirRu3VpOnjwpIiIvvviizJ49W5577jlp166d/Otf/5IXX3xRgoKCxMnJSVJTU8XBwUFatGghOp1OYmJiJCIiQkpKSqRVq1bSq1cvCQsLkwkTJoijo6Pk5uaKra2t2Nrayo4dO6Rp06YCQDZt2iQiIiEhIWJkZCQuLi5iZmYmHTp0kA4dOsiBAwfEzc1NgoODRUTE29tbjhw5UinQ2tvby9tvvy3Hjh0TExMTGThwoHz22WeSk5OjnXvZQhwfffSRNGrUSFtYpCwc5eXliVJKzp07JwUFBWJjYyMNGjQQFxcXMTQ0lL///e8iIuLm5ia2trbyzTffSMeOHcXNzU1OnDghDg4OWqAdM2aM1sagoCAZPXq0jBo1SkaOHKnVGx0dLe7u7rJ06dIK98jFxUXGjh0rr7zyioiING7cWE6fPi0HDhwQQ0ND+e2336SwsFACAwPF2NhYWwhm48aNMmrUKLl586aMGjVKOnToIElJSXL27FntPl69elVefPFFiYqKEl9fX7G2thZPT0+xt7eX/Pz8ahcyedjFVMoH2pYtW1b5h0WZ6haBEflP4LrfIjpVLRRzb6C1srKSrKwsycvLk7Zt28qvv/4qGRkZ0q5dO7l+/boUFBRI586dqwy02dnZUlhYKCIi33//vQwYMKBSmUWLFklkZKSIlC6wc+vWLbl69ar4+flJbm6uiPxncRwR0e7BvcoWzin/+1cW2O8No2WSk5PF0dFRbt++LdnZ2dK+ffsKgXbChAla2fsF2kaNGklmZqbk5+eLhYWFzJkzR0RElixZon0GHR0d5dKl0gdWVd3LR8VAW7s/7HJARHpr6y8ZcF0QC8fIn3DNbxpu5xXgx7if0LVrV8ybNw/r1q2DlZWVNufwqFGjkJiYqHXRCQ4OhoGBAaysrPD8889r06sZGxujqKgIe/bs0Rbs+O2333Dq1Clcv34dGRkZCAkJQf369WFkZISePXsiMTERDRo0gImJCa5fL11G28XFBcbGxkhISEBRURGMjY1hbGyMcePG4c6dO0hPT0d8fDyKi4vh6OhY6fzs7OxgYGAAe3t7GBoaYuLEiTh06BA8PT21r1yXLl0KFxcXREZG4s6dO9qiJ0DpXM1paWlQSsHKygqff/45WrRoAT8/P6SkpMDAwAAvvPACAGDatGnIzMzE8uXL4erqiuDgYNSrV69Ce+6df7t8f9ejR4/Cz88PCxcuxKlTp6qc8m7v3r2YOHGi9trc3BypqakwMzND8+bNUadOHQwfPhwlJSXaQjDLly9HRkaGdm8MDAy0f5Zvj4GBAYqLi1GnTh2kpqbC0tISJSUlmDBhQrULmTzsYirlOTs7Y/jw4VizZk21835XtQhMeSJVL6LzsAvFdOvWDY0aNUK9evVgb2+PCxcuIDExEQEBAWjSpAmMjIwQGhpaZduys7MRGhoKR0dHTJkypcr75OnpiZUrV2LevHk4cuQIGjRogAMHDuD48ePw9fWtsDjO/Zw8ebLS71/ZUuHV2bNnD0JCQmBqaoqGDRsiODi4wvuDBw++7/7lz6Fly5YwNjZG+/bt0bNnTwAVF7Hx9fVFWFgYPv74YxQXF9/naKQPGGiJSC9t/SUDUzel4uad0n6oeaf3w8ypGywmr8P/W/gv+Pr6olWrVsjOzq72GGWBSClVKRx5e3vjxIkTeP3117FkyRI4ODjg3LlzcHNzq/Z4ZQuirF69Gl988QXq168Pc3NzbN68Gebm5vjll1+watUqpKSk4MSJExg5ciSGDRtW7RzSZYGppKQEJSUlCAwMxNtvv43s7Gzk5uYiPj4eu3btwv79+7FgwQIopfDbb79Vmqu5THZ2NszNzaGUQlxcnNaHFyidzzk/Px+HDh1C+/btUb9+/QfcgVJt2rTBTz/9hJEjR2LJkiWwsbGBp6dnhQVBgNIFSW7evAkA+Oabb7R/r4qpqSn+/e9/45dffsGtW7dw8uRJjBkzptprVBasCwoKUFhYiJKSEtjb26NPnz44dOhQtQuZiJQuppKSkoKUlBQcOXIEsbGx9z3fr7/+uso/LMqrbhGYMuUX0UlJScEzzzyjXa+yhWJWrlxZ7UIx9/5h8Sj9SWfPno3AwEAcPXoUX331VaX7BJTeq927d6NVq1YICwvD6tWrISLo0aOHdq2OHz+OTz/99KHrrSnlP5fl731JSQkKCgq09+79fS6/qE3Z9Vq2bBkiIyNx8eJFuLu7a3+Ikn5ioCUivRT13UkUFpcOLCq8fgk5h2NhauuDwhLB2m/2oF27dhg2bBjOnTunLejx2Wef4fnnn3+o40+bNg0igilTpmDq1KlYtWoVMjIycPv2bVhZWWHr1q24c+cOSkpKEBsbCy8vLwCl/8PcsWMHFi9ejGPHjmHAgAFYu3Ytbt26hTZt2mDbtm0QKV10Zfjw4bh58yaGDh1637YUFxcjPz8fTk5OcHV1xeTJk2Fubl5h0ZPLly+jqKgIc+bMgbOzMwYOHAgPDw/Y2dlBRJCeno7hw4fjwIED2L17N1avXo3GjRtj69atAIB9+/ahUaNGGDJkiPYU9GE0atQIM2fOxKVLlxAREYG2bdvi3LlzlcrNnTsXdevWhbe3N7788ku0bdsWWVlZ0Ol0uHPnDq5du4bi4mKsXbsW48aNQ+/evdG1a1d4eHjA1dVVWwjGxMSkwlzVlpaWOHjwIADg559/xu+//44uXbpg2bJl+OKLL7T5touKirBs2bIKbXrYxVTKlJSU4OLFi5X+sLhXdYvAlLnfIjoPWiimOp6envjpp59w8+ZNFBUVYfPmzVWWy87ORqtWpXOwx8TEVFnmwoULeOaZZxAREYExY8bg0KFD1S6OA1S/eI2dnR3S09Mr/P4FBATc9zz8/f2xdetW5OXlIScnB1999VW1Zcvf++3bt1f4A+1hnD17Fs8//zwWLFiA5s2b4+LFi4+0Pz1ZntqFFYhIv2Vm/Weqn5LCfBgoA9z88RPcjF8Jo8YtMW/DdjRr1gw6nQ6hoaEoKiqCp6cnZs6cifnz58PS0hJA6f/UY2JikJycDEtLSxw9ehSWlpZo3Lgx9u3bh+joaHzyyScYPnw4zMzMsGbNGrRv3x7vvfcevLy8YGBggLFjx6JPnz5wcHBA3759YW5ujqSkJCxatAi5ubn49ttvcf78eUyYMAGbN2/GunXrMGTIENjb22PQoEEwNzev8hz/9re/adM1mZiY4MiRIxXeL7/oiYmJCZ599lksWbIEXbp00cqYmJhg27ZtCAoKQv369TFo0CDk5ORg5cqVuHHjRoVFQJo2bYqXXnpJW+mu7HrEx8ejdevW+Oc//6mFoB07dmDevHkAgGHDhqG4uBjvvPMOvvrqK3Tq1KnSuTRt2hRHjhzBxIkTsX//fpibm+Pw4cMYMGAAVq1ahcDAQIgI+vTpg7ffflt7cl32df1bb72F3r17Y/PmzRg/fjxMTEyQlJSE5ORkvPTSS2jYsCG6dOmiPbmeN28ezMzM0Lt3bwClT/PGjx9foU0Pu5hKmeLiYowYMQLZ2dkQEe0Pi3tVtwhMmfstovOghWKq06pVK8ycORNeXl5o0qQJOnTogEaNGlUqN23aNIwaNQqRkZHVLjITHx+PqKgoGBkZwczMDKtXr77v4jhjx45FUFAQLCwsEBcXpx2nXr16WLlyZYXfv3vvwb3c3NwwePBguLi4oEWLFvddXCYiIgL9+vWDi4uL9vl+FFOnTsXp06chIujWrRtcXFyQmZmJMWPGYOfOnY90LKp9XFiBiPSS78IfkZFV9fyVrcxNsHdG17+4RY/m5ZdfxjfffIOdO3dqfQwfR1ko/+c//1npvdzcXJiZmUFEMHHiRNjY2GDKlCna+8ePH0ffvn0REhLyh6bA+/vf/45du3YhPz8fPXv2RHR0dKWv2Z8W97sPD+NxFoopu89FRUUICQlBeHg4QkJC/lA76NFxYYXaxSe0RKSXpvayw9RNqVq3gzJGBuqJnTe6vPfff79GjxcWFqbNxXqvjz/+GKtWrUJBQQFcXV0xbty4Cu+Xzef8R3Hi+5pR/g+LP7JQzLx58yr8YdG/f/8/oZVETyY+oSUivbX1lwzM/+qYNjDM3MQI84Id0N+1VS23jIieNnxCW7v4hJaI9FZ/11YMr0RExFkOiIiIiEi/MdASERERkV5joCUiIiIivcZAS0RERER6jYGWiIiIiPQaAy0RERER6TUGWiIiIiLSawy0RERERKTXGGiJiIiISK8x0BIRERGRXmOgJSIiIiK9xkBLRERERHqNgZaIiIiI9BoDLRERERHpNQZaIiIiItJrNRJolVJBSqmTSqkzSqkZ9yk3UCklSimPmqiXiIiIiOixA61SyhDABwB6A7AHMFQpZV9FuQYAXgHw8+PWSURERERUpiae0HoBOCMi50SkAMA6AP2qKPd/AN4GkF8DdRIRERERAaiZQNsKwMVyry/d3aZRSrkBaCMiX9/vQEqpsUqpZKVU8tWrV2ugaURERET03+5PHxSmlDIA8B6A//egsiKyXEQ8RMSjefPmf3bTiIiIiOi/QE0E2gwAbcq9bn13W5kGABwBxCul0gF4A9jOgWFEREREVBNqItAmAbBRSlkppeoCGAJge9mbIpItIs1ExFJELAEcABAsIsk1UDcRERERPeUeO9CKSBGASQC+A3ACwAYROaaUWqCUCn7c4xMRERER3U+dmjiIiOwEsPOebXOqKdulJuokIiIiIgK4UhgRERER6TkGWiIiIiLSawy0RERERKTXGGiJiIiISK8x0BIRERGRXmOgJSIiIiK9xkBLRERERHqNgZaIiIiI9BoDLRERERHpNQZaIiIiItJrDLREREREpNcYaImIiIhIrzHQEhEREZFeY6AlIiIiIr3GQEtEREREeo2BloiIiIj0GgMtEREREek1BloiIiIi0msMtERERESk1xhoiYiIiEivMdASERERkV5joCUiIiIivcZAS0RERER6jYGWiIiIiPQaAy0RERER6TUGWiIiIiLSawy0RERERKTXGGiJiIiISK8x0BIRERGRXmOgJSIiIiK9xkBLRERERHqNgZaIiIiI9BoDLRERERHpNQZaIiIiItJrDLREREREpNcYaImIiIhIrzHQEhEREZFeY6AlIiIiIr3GQEtEREREeo2BloiIiIj0GgMtEREREek1BloiIiIi0msMtERERESk1xhoiYiIiEivMdASERERkV5joCUiIiIivcZAS0RERER6jYGWiIiIiPRajQRapVSQUuqkUuqMUmpGFe+/ppQ6rpQ6rJT6QSnVribqJSIiIiJ67ECrlDIE8AGA3gDsAQxVStnfU+wXAB4i4gxgE4B3HrdeIiIiIiKgZp7QegE4IyLnRKQAwDoA/coXEJE4Eblz9+UBAK1roF4iIiIiohoJtK0AXCz3+tLdbdV5CcA3NVAvERERERHq/JWVKaVGAPAAEFDN+2MBjAWAtm3b/oUtIyIiIiJ9VRNPaDMAtCn3uvXdbRUopboDmAUgWER+r+pAIrJcRDxExKN58+Y10DQiIiIi+m9XE4E2CYCNUspKKVUXwBAA28sXUEq5AvgIpWH2txqok4iIiIgIQA0EWhEpAjAJwHcATgDYICLHlFILlFLBd4tFATADsFEplaKU2l7N4YiIiIiIHkmN9KEVkZ0Adt6zbU65f+9eE/UQEREREd2LK4URERERkV5joCUiIiIivcZAS0RERER6jYGWiIiIiPQaAy0RERER6TUGWiIiIiLSawy0RERERKTXGGiJiIiISK8x0BIRERGRXmOgJSIiIiK9xkBLRERERHqNgZaIiIiI9BoDLRERERHpNQZaIiIiItJrDLREREREpNcYaImIiIhIrzHQEhEREZFeY6AlIiIiIr3GQEtEREREeo2BloiIiIj0GgMtEREREek1BloiIiIi0msMtERERESk1xhoiYiIiEivMdASERERkV5joCUiIiIivcZAS0RERER6jYGWiIiIiPQaAy0RERER6TUGWiIiIiLSawy0RERERKTXGGiJiIiISK8x0BIRERGRXmOgJSIiIiK9xkBLRERERHqNgZaIiIiI9BoDLRERERHpNQZaIiIiItJrDLREREREpNcYaImIiIhIrzHQEhEREZFeY6AlIqInwtatW6GUQlpaWq22Y8yYMTh+/Pgf2nf79u1YuHBhle+ZmZkBADIzMzFo0KA/3L6alp6eDkdHxyrfmzNnDnbt2gUAWLJkCe7cufNIx+7SpQuSk5Mfu41PK6XUPKXU3//E48crpTz+rOP/UUqpLkqpHY+yDwMtERE9EdauXYvOnTtj7dq1tdqOTz75BPb29o+8X1FREYKDgzFjxoz7lrOwsMCmTZv+aPP+UgsWLED37t0B/LFA+ziKior+srro0Sml6tR2G8pjoCUiolqXm5uLhIQEfPrpp1i3bl2VZdLT09GhQweEhYXB1tYWw4cPx65du+Dr6wsbGxskJiYCABITE+Hj4wNXV1d06tQJJ0+eBADExMRgwIABCAoKgo2NDaZNm1ZlPWVPFYuLixEWFgZHR0c4OTlh8eLFlcqGhYVh/PjxeP755zFt2jTExMRg0qRJAIDz58/Dx8cHTk5OeOONNyqcR9kT0fu16dNPP4WtrS28vLwQERGhHbe86s61vIkTJ2L79u0AgJCQEISHhwMAVqxYgVmzZgEAiouLERERAQcHB/Ts2RN5eXna+W3atAlLly5FZmYmAgMDERgYCACIjY2Fj48P3NzcEBoaitzc3Cqv58aNG+Hl5QVbW1vs2bMHAJCfn4/Ro0fDyckJrq6uiIuL065HcHAwunbtim7duuHy5cvw9/eHTqeDo6Ojtv/D1J2SkgJvb284OzsjJCQEN2/e1O7v9OnTK7WpvNzcXHTr1g1ubm5wcnLCtm3btHvXsWPHKq9VeUqp5kqpzUqppLs/vne3z1NKrbj7ZPScUmpyuX1GKqUOK6VSlVKfVXFMnVLqwN0yW5RSje9un6yUOn53+7q72+rfrSdRKfWLUqrf3e0mSql1SqkTSqktAEyqumdKqf9RSqUppQ4qpZaWPS292/7PlFJ7AXymlLJUSv14t+4flFJt75aLUUoNKne83Lv/7HL33DfdPf7nSil1972gu9sO4f+3d+fxVVXnwsd/TwIyyiBahzAFC6SB0AQCGgOSFFQUZY7ABd8ERF+rDFduRbDFUoeKhVZEvaUtSihQBKQgvfiCoszVCwECSDRKIRAjZZJEg0EyPO8fe+d4SE6SA4kJJzzfz+d8svc6a+/97JVAnqyz9lowxFdc5VLVy/LVrVs3NcYYc2VYvHixjh07VlVVY2JiNCUlpVSdw4cPa3BwsO7bt08LCwu1a9euOmbMGC0qKtLVq1frwIEDVVU1JydH8/PzVVX1vffe0yFDhqiq6oIFCzQ0NFSzs7M1Ly9PW7durUePHi11nd69e+vOnTs1JSVF+/bt6yk/c+ZMqbqJnXSvZAAAIABJREFUiYnav39/LSgo8FzjscceU1XV++67TxcuXKiqqq+++qo2atTIcx+dOnUqN6asrCxt06aNnj59Ws+fP689e/b0nNdbWffqbenSpfqLX/xCVVW7d++ut9xyi6qqJiUl6bp16zztumfPHlVVTUhI0EWLFnnub8WKFaqq2qZNGz158qSqqp48eVJ79eqlubm5qqo6c+ZM/c1vfuOzLSdPnqyqqmvXrtU+ffqoqurs2bN1zJgxqqr6ySefaKtWrTQvL08XLFigISEhevr0aU+95557TlVVCwoK9Ouvv/b72hEREbpp0yZVVZ0+fbpOmjSp3Ji85efna05Ojudeb775Zi0qKiq3rYAUdXMY4G9AT3e7NfCJuz0D+CdQD7gWOA3UBToBnwHXuvWu8ar/C3d7H9Db3X4GmONufwnUc7ebuV9/C4wuLnPP3QiYDLzhlncBCoBo9cq/gPpAJhDq7i8F/scrnl1AA3f/H0Ciuz0WWO1uJwPDvM6Z636NA3KAljidqh8CPb2u2R4QYHnxNf19XVbdxcYYY65MS5cuZdKkSQCMGDGCpUuX0q1bt1L1QkNDiYiIAKBTp0706dMHESEiIoKMjAwAcnJySExM5PPPP0dEyM/P9xzfp08fmjZtCkB4eDhHjhyhVatWPmNq164dhw4dYsKECfTv358777zTZ72EhASCg4NLlW/fvp2VK1cC8MADD/Dkk0/6PN5XTKdOnaJ3795cc801nmt89tlnpY4t716L9erVizlz5pCWlkZ4eDhnzpzh2LFjfPjhh8ydO5fTp08TGhpKZGQkAN26dfO0ZVk++ugj0tLSiI2NBeD8+fPExMT4rDtkyJBS5922bRsTJkwAICwsjDZt2nju74477vDcd/fu3Rk7diz5+fkMGjSIyMhINm/eXOG1c3JyyM7Opnfv3gAkJiaSkJBQbkzeVJWnnnqKLVu2EBQURFZWFsePHwfwt636AuFu5yNAExFp7G6vVdXvgO9E5ARwPfAzYIWqnnKv/5X3yUSkKU6yutktWgiscLf3AUtEZDWw2i27ExjgNf62Pk5ifTsw173GPhHZ5yP2MOCQqh5295cCD3u9v0ZVi7ulY/i+N3UR8DtfjVHCDlX9wr2vVKAtkAscVtXP3fLFJa5ZIUtojTHG1IjVe7KYtT6dzGMnyHp3Azt2pdKwXh0KCwsREWbNmoVXQgBAvXr1PNtBQUGe/aCgIM+Yy+nTpxMfH8+qVavIyMggLi7O5/HBwcHljtNs3rw5e/fuZf369cybN4/ly5fzxhtvlKrXqFGjMs9RMn5fLiamksq712IhISFkZ2ezbt06br/9dr766iuWL19O48aNufrqqzl9+nSpGHx9jO5NVbnjjjv8Gu9cfG5/7827PW+//Xa2bNnC2rVrSUpKYvLkyTRv3tzva19qTEuWLOHkyZPs2rWLunXr0rZtW86dO3fBscXHl9FWQcCtqnrOu9D9efjOq6iQyudi/XES1fuAX4pIBE4v51BVvWAMij8/j34460edAtxhrSISBFzl9V5V3z9gY2iNMcbUgNV7spj29/1kZedxNn07DcPjaTFuPnNWbSczM5PQ0FCfYxv9kZOTQ0hICOCMybxUp06doqioiKFDh/Lcc8+xe/fuizo+NjbWMx54yZIlF3Vs9+7d2bx5M2fOnKGgoMDT01uSv/d66623MmfOHG6//XZ69erF7Nmz6dWr10XFdPXVV/PNN994zrd9+3YOHjwIwNmzZ332IJelV69enjb57LPPOHr0KB07dixV78iRI1x//fU89NBDjBs3jt27d/t17aZNm9K8eXPPz9CiRYs8vbX+yMnJ4Uc/+hF169Zl48aNHDlyxO9jXe8CE4p3RCSygvofAAki0sKtf433m6qaA5wRkeJv2gPAZjdZbKWqG4EngaZAY2A9MMFrfGqUe9wW4D/css44ww5KSgfaiUhbd394OXH/Exjhbo8Civ/RZgDFH7EMwBlWUZ5PgbYicrO7P7KC+qVYQmuMMabazVqfTl5+IQBnP9lMww4x5OUXMmu906E0dOjQS+6BmzJlCtOmTSMqKqpST8pnZWURFxdHZGQko0eP5oUXXrio419++WVee+01IiIiyMrKuqhjQ0JCeOqpp+jRowexsbG0bdvWMyzBm7/32qtXLwoKCvjxj39M165d+eqrry46oX344Yfp168f8fHxXHfddSQnJzNy5Ei6dOlCTEzMRU239uijj1JUVERERATDhw8nOTn5gp7PYps2beKnP/0pUVFRLFu2jEmTJvl97YULF/LEE0/QpUsXUlNTefrpp/2Ob9SoUaSkpBAREcFf//pXwsLC/D7WNRGIdh+WSgMeKa+yqh4AnsdJUvcCf/BRLRGY5Q4TiMQZRxsMLBaR/cAeYK6qZgPP4iSR+0TkgLsP8EegsYh84h6/y0csecCjwDoR2QV8gzPu1ZcJwBg3pgeASW75X4De7r3EUEGvrtuT/TCw1n0o7ETxeyISLSLzyzseQNxBupUiIv2Al3Eadr6qzizxfj3grzjZ+mlguKpmlHfO6OhotbnrjDGmdgqduhZfv30EODyzf3WHc1nKzc2lcePGFBQUeGYnGDx4cE2HZcogIrtU9bKb0/VSiEhjVc11e3hfAz5X1dLTfFxGKt1DKyLBODd7NxAOjBSRkhP4PQicUdUfAy8BL1b2usYYYwLXTc18zhZUZvmVaMaMGZ7pqkJDQxk0aFBNh2SuHA+5D2wdwBnG8KcajqdCVTEQtwdwUFUPAbhzoA0EvJdZGYgz1QPAW8CrIiJaFd3DxhhjAs4Td3Vk2t/3e4YdADSoG8wTd5UeR3mlmj17dk2HYK5Qbm/sZd0jW1JVjKENwZk7rNgXbpnPOqpagDMWo0UVXNsYY0wAGhQVwgtDIghp1gABQpo14IUhEQyKKvnrwxhjKnZZTdslIg/jzjvWunXrGo7GGGPMD2lQVIglsMaYKlEVPbRZgPes1C3dMp913LV/m+I8HHYBVf2zqkaravR1111XBaEZY4wxxpjarioS2p1AexEJFZGrcOYjW1Oizhqc6SYAhgEf2PhZY4wx1Wn16tWIyEVNL/VDGDduHGlpaRVX9GHNmjXMnDnT53uNGzsLUX355ZcMGzbskuO7WJs2beLee++ttusZ40ulE1p3TOx4nEl8PwGWq+oBEXlGRAa41V4HWojIQZx1hKdW9rrGGGPMxVi6dCk9e/as1ApTVWH+/PmEh5ecDKhiBQUFDBgwgKlTy/8VetNNN/HWW29danjVrrCwsOJKxlSgShZWUNV3VLWDqt6sqs+7ZU+r6hp3+5yqJqjqj1W1R/GMCMYYY0x1yM3NZdu2bbz++uue1btKysjIICwsjKSkJDp06MCoUaPYsGEDsbGxtG/fnh07dgCwY8cOYmJiiIqK4rbbbiM93VkMIjk5mSFDhtCvXz/at2/PlClTfF4nLi6OlJQUCgsLSUpKonPnzkRERPDSS6UfKk9KSuKRRx7hlltuYcqUKSQnJzN+/HgADh8+TExMDBEREfzqV7+64D46d+5cYUyvv/46HTp0oEePHjz00EOe83or6159te+wYcMICwtj1KhRFH8I+/777xMVFUVERARjx47lu++cVU/btm3Lk08+SdeuXVmxYgVz584lPDycLl26MGKEs/DU2bNnGTt2LD169CAqKoq3337b57WNAZz1mC/HV7du3dQYY4ypCosXL9axY8eqqmpMTIympKSUqnP48GENDg7Wffv2aWFhoXbt2lXHjBmjRUVFunr1ah04cKCqqubk5Gh+fr6qqr733ns6ZMgQVVVdsGCBhoaGanZ2tubl5Wnr1q316NGjpa7Tu3dv3blzp6akpGjfvn095WfOnClVNzExUfv3768FBQWeazz22GOqqnrffffpwoULVVX11Vdf1UaNGnnuo1OnTuXGlJWVpW3atNHTp0/r+fPntWfPnp7zeivrXr1t3LhRmzRpopmZmVpYWKi33nqrbt26VfPy8rRly5aanp6uqqoPPPCAvvTSS6qq2qZNG33xxRc957jxxhv13LlzF7TDtGnTdNGiRZ6y9u3ba25ubqnrXy6AFL0M8qcr9WVL3xpjjKn1li5d6un5GzFiRJnDDkJDQ4mIiCAoKIhOnTrRp08fRISIiAgyMjIAyMnJISEhgc6dO/P4449z4MABz/F9+vShadOm1K9fn/DwcI4cOVJmTO3atePQoUNMmDCBdevW0aRJE5/1EhISCA4OLlW+fft2Ro50lrx/4IEHyryOr5h27NhB7969ueaaa6hbty4JCQk+jy3vXr316NGDli1bEhQURGRkJBkZGaSnpxMaGkqHDh0ASExMZMuWLZ5jhg8f7tnu0qULo0aNYvHixdSp40zA9O677zJz5kwiIyOJi4vj3LlzHD16tMz7NFe2y2raLmOMMaaqrN6Txaz16WQeO0HWuxvYsSuVhvXqUFhYiIgwa9YsnJU9v1evXj3PdlBQkGc/KCiIgoICAKZPn058fDyrVq0iIyODuLg4n8cHBwd7jvGlefPm7N27l/Xr1zNv3jyWL1/OG2+8Uapeo0aNyjxHyfh9uZiYSirvXit7De/7Wrt2LVu2bOEf//gHzz//PPv370dVWblyJR072mIbpmLWQ2uMMabWWb0ni2l/309Wdh5n07fTMDyeFuPmM2fVdjIzMwkNDWXr1q2XdO6cnBxCQpz5c5OTky85xlOnTlFUVMTQoUN57rnn2L1790UdHxsb6xkPvGTJkos6tnv37mzevJkzZ85QUFDAypUrfdarzL127NiRjIwMDh48CMCiRYvo3bt3qXpFRUVkZmYSHx/Piy++SE5ODrm5udx111288sorOJ/mw549ey7q+ubKYgmtMcaYWmfW+nTPsrpnP9lMww4x5OUXMmu981DT0KFDL3m2gylTpjBt2jSioqIuqrezpKysLOLi4oiMjGT06NG88MILF3X8yy+/zGuvvUZERARZWSWnfy9fSEgITz31FD169CA2Npa2bdvStGnTUvUqc6/169dnwYIFJCQkeIZxPPLII6XqFRYWMnr0aCIiIoiKimLixIk0a9aM6dOnk5+fT5cuXejUqRPTp08HnGnJ7rnnnouKxdR+UvyXz+UmOjpaU1JSajoMY4wxASh06lp8/XYT4PDM/tUdzmUpNzeXxo0bU1BQwODBgxk7diyDBw+u6bAClojsUtXomo7jSmU9tMYYY2qdm5o1uKjyK9GMGTOIjIykc+fOhIaGMmjQoJoOyZhLZg+FGWOMqXWeuKsj0/6+3zPsAKBB3WCeuMseMCo2e/bsmg7BmCpjCa0xxphaZ1CU8yDTrPXpfJmdx03NGvDEXR095caY2sUSWmOMMbXSoKgQS2CNuULYGFpjjDHGGBPQLKE1xhhjjDEBzRJaY4wxxhgT0CyhNcYYY4wxAc0SWmOMMcYYE9AsoTXGGGOMMQHNElpjjDHGGBPQLKE1xhhjjDEBzRJaY4wxxhgT0CyhNcYYY4wxAc0SWmOMMcYYE9AsoTXGGGOMMQHNElpjjDHGGBPQLKE1xhhjjDEBzRJaY4wxxhgT0CyhNcYYY4wxAc0SWmOMMcYYE9AsoTXGGGOMMQHNElpjjDHGGBPQLKE1xhhjjDEBzRJaY4wxxhgT0CyhNcYYY4wxAc0SWmOMMcYYE9AsoTXGGGOMMQHNElpjjDHGGBPQLKE1xhhjjDEBzRJaY4wxxhgT0CyhNcYYY8wVYfXq1YgIn376aY3GISLzRST8Bzp3pIjc47U/QESmVtG5w0QkVUT2iMjNlTzXDBH5RVXEBZbQGmOMMeYKsXTpUnr27MnSpUtrNA5VHaeqaT/Q6SMBT0KrqmtUdWYVnXsQ8JaqRqnqv6ronFXCElpjjDHGXOBy6ckcN24caWlVk/fl5uaybds2Xn/9dd58801SU1N55513PO+vWbOGJ598krCwMJKSkujQoQOjRo1iw4YNxMbG0r59e3bs2AHAjh07iImJISoqittuu4309HQARCRJRP4uIutE5HMR+Z2vWERkk4hEi0iwiCSLyMcisl9EHveq00xEHhWR60RkpYjsdF+x7vs9RORDt7f0nyLSUUSuAp4Bhrs9qcPdmF51j0kWkblu/UMiMswtDxKR/xaRT0XkPRF5p/g9r3juAf4T+LmIbHTLJruxfywi/+lVt6zyX4rIZyKyDeh46d9NH1T1snx169ZNjTHGGFP97r//fu3Zs6c+/fTTNR1KlVm8eLGOHTtWVVVjYmL017/+tT722GMX1Dl8+LAGBwfrvn37tLCwULt27apjxozRoqIiXb16tQ4cOFBVVXNycjQ/P19VVd977z0dMmSIAilAEnAIaArUB44ArbREjgNsAqKBbsB7XuXNvLbbAh8DfwN6umWtgU/c7SZAHXe7L7DS3U4CXvU6j2cfSAZW4HRohgMH3fJhwDtu+Q3AGWCYj7hnAL9wt7sB+4FGQGPgABDlR3lDN/aDxeeqiledS0uDjTHGGFMbFfdkbty4kfvuu4/f/OY3pepkZGTQr18/br31Vv75z3/SvXt3xowZw69//WtOnDjBkiVL6NGjBzt27GDSpEmcO3eOBg0asGDBAjp27EhycjJr1qzh22+/5V//+heDBw/md78r3ZkZFxfH7NmziYqK4sEHHyQlJQURYezYsTz++OMX1D158iSPPPIIR48eBWDOnDnExsZ6YkhLS6Nly5akp6czbNgwZsyYQb169di2bRvTpk0jLy+PDz74gNDQUH7/+9/TpEkTMjMzyczMZOXKlXTt2pXDhw/z6KOP8u677/L111+Tl5dH8+bNadiwoXco7wNvA3uB5sBmERmhqjtEpAfwMtAZeB0YB7QTkSU4CW6eiAQBQ4FngZtxejL7isi/gVCgnogcAP4A3Csi7QEF6vr5LV6tqkVAmohc75b1BFa45f8u7oGtQE9glaqeBRCRvwO9ACmjPMgt/9YtX+NnvH6xIQfGGGOM8Xj77bfp168fHTp0oEWLFuzatctnvYMHD/Jf//VffPrpp3z66af87W9/Y9u2bcyePZvf/va3AISFhbF161b27NnDM888w1NPPeU5PjU1lWXLlrF//36WLVtGZmZmmTGlpqaSlZXFxx9/zP79+xkzZkypOpMmTeLxxx9n586drFy5knHjxrF6TxYT3jnOF9Hjyc37jqxjx+natSsvvfQSdevW5f777yc1NZXhw4d7zlOvXj0Ajh07xt133820adOYOnUqQUFBfPXVV2RkZBAbG8vEiROpU6cOU6dO5dy5c96hfOd+bQhsAeYAb7hln+Ikd7uAPwFTgZ/iJL7fALtxEtsv3Pf+BeTg9Mx2BUJU9SqgN/ASsFFVOwP34fQI++M7r23x85jLniW0xhhjjPFYunQpI0aMAGDEiBFlPkAVGhpKREQEQUFBdOrUiT59+iAiREREkJGRAUBOTg4JCQl07tyZxx9/nAMHDniO79OnD02bNqV+/fqEh4dz5MiRMmNq164dhw4dYsKECaxbt44mTZqUqrNhwwbGjx9PZGQkAwYM4MTpMzz55g6yTpzm+PKnIbgu5+pcTfMf3UhmZibXXnstx44dK/OagwYNQkRo1aoVx48fB+Dbb78lISGBr7/+mp/85CfEx8ezadOmMpvS/boPaCIizXCGIqwAugOTgS44udhioBnQD2ijqnle53kXmICTfP5WRD4DNuB8pH/WrZPkVf8b4Ooyb8y37cBQdyzt9UCcH8dsBQaJSEMRaQQMdsvKKt/iljcQkatxkvAqY0MOjDHGmCvc6j1ZzFqfTuaxE2S9u4Edu1JpWK8OhYWFiAizZs1C5MLOvOKeTICgoCDPflBQEAUFBQBMnz6d+Ph4Vq1aRUZGBnFxcT6PDw4O9hzjS/Pmzdm7dy/r169n3rx5LF++nDfeeOOCOkVFRXz00UfUr+90VMbO/ICs7Dyyty6mKD+Pa+97grotWnLqTaeXODo6mr1795Z5Te/43DGjHlOmTCExMZETJ07Qp0+fsk6hPvafBTbi9Mj+HpiHM542CDgPvAe8IyL/F2csLsBE4DV3vwmwTFUfFpFjwC9FZDyw1us6G4GpIpIKvFDmDV5oJdAHSAMycXqKc8o7QFV3i0gysMMtmq+qe8B5+KyM8mU4QzFOADuLzyUij7jnnOdnvKVYD60xxhhzBVu9J4tpf99PVnYeZ9O30zA8nhbj5jNn1XYyMzMJDQ1l69atl3TunJwcQkJCAEhOTr7kGE+dOkVRURFDhw7lueeeY/fu3aXq3Hnnnbzyyiue/cPpTm9w0Xdnad47iQbtupG7fwMFRU6eOWTIELp163bBOZo0acLHH3/s2U9OTmbYMOdh/7Zt2zJv3jxWrlzJLbfcwtatWwkKCmLkyJGeHmlVTVbV8e7hw1X1XqAAyFHVHJwe2ixVjcN5SCpfVbsCQ4BOqvpznPG3XXB7WlX1lKoOB2YDf3WT2Xich7d+ps4UWr9S1bZuDF+pandVjVTVZd4xqWqSqr5VfH+q2tj9WoTzgFYYMAJnrO7+km2sqjNUdbbX/h9UtbP7muNH+fOq2kFVe6rqfxSfS1XnVSaZBUtojTHGmCvarPXp5OUXAnD2k8007BBDXn4hs9Y7U1ENHTr0kudtnTJlCtOmTSMqKqrcHtiKZGVlERcXR2RkJKNHj+aFF0p3PM6dO5eUlBS6dOlCeHg4RWnvAtD0lqFkb17IlwsmokVF1Alyeprj4+NJS0sjMjKSZcuW+RXH0KFDadmyJeHh4YwePZquXbvStGnTsqqfE5E9OL2wD7plvwNecMu9PyW/H/jY7VXtjJO4nga2u1NfzQKWANEish/4PzjjcQFwp9m6ya+bKNv/uNffCjyrqv+u5PmqlZTsRr9cREdHa0pKSk2HYYwxxtRqoVPXcvazDzm56nluGvdH6rZoBTgDNg/P7F+tsYwbN47JkycTHl75RbSKe56Lk/Xzxw8RfO4Mr0x5kEFRIaxZs4a0tDSmTr24RbRyc3Np3Lgxp0+fpkePHmzfvp0bbrgBEdmlqtHgzDOL0+NZYSLjJqJzVXVYRXWrkojUwxmqcC3wgqou83pvE37GX8kYquw6lRpDKyLXAMtw5krLAO5X1TMl6kQCf8QZ91EIPO/daMYYY4ypOTc1a0DqJ1uo1zKcs2lbaNZrlKe8us2fP7/KzjUoyhnqMGt9Ol9m59EoN5P2QSc85QMGDGDAgAEXfd57772X7Oxszp8/z/Tp07nhhhsqFaeqfokzD2x1i3KvH3kpB4tIHVW99G73KlbZIQdTgfdVtT3OvGu+/sz5Fvg/qtoJ5+m9Oe6TfsYYY4ypYeN7teR8Vhot7p7E2U+3ANCgbjBP3PX9Qk4ZGRmVWkErOTmZIUOG0K9fP9q3b8+UKVN8xhIXF0dKSgqFhYUkJSXRuXNnIiIieOmll0rVPXnyJEOHDqV79+50796d7du3l4rhd48l8MbgENKfuYPv/vdNdn6w1jPEIDk5mfHjneGuSUlJTJw4kdtuu4127drx1lvOMNOioiIeffRRwsLCuOOOO7jnnnsYP348qamppKWlkZSUBMBf/vIXgJ+IyF4RWQncU7LXUURmiMgid3Wvz0XkIbe8rYh87G4Hi8gsd0Wwfe7DYcXHP+muJrZXRGa6ZTe7q5LtEpGtIhJWsp1E5BoRWe2e7yMR6SIiP8KZWaG7u6LYzT6+HQ+4733szp/rfQ/bgUVyEauYueUNRORNEflERFYBVfdXU2VWZQDSgRvd7RuBdD+O2Qu0r6ierRRmjDHG/PAWL16sfQYO19teeF/r3RSmXcb/UVft/uKCOpVZQUtVdcGCBRoaGqrZ2dmal5enrVu31qNHj5aKpXfv3rpz505NSUnRvn37esrPnDlTqu7IkSN169atqqp65MgRDQsLqzAG75XBvPcTExN12LBhWlhYqAcOHNCbb75ZVVVXrFihd999txYWFuqxY8e0WbNmumLFilKxnDp1SoEUdfKc54AJ6nuVrb1uEnctzmwCN+GuCObWeRj4lbtdD2f1sVDgbuCfQEP3vWvcr+8X51TALcAHPq77CvBrd/tnQKq7HQf8T8n6+v1KZn9xt2/3im8Gzhy6Ddz9i13FbDLwhrvdBeeBuWhfMVzsq7LTdl2vqsWTuP0buL68ym6GfxXORMHGGGOMqQHF03R9mZ1HzupXmDhpEjN+/jPmNvw5R48e9Hws76143lmg3HlnExMT+fzzzxER8vPzPccXzzsLeOadbdWqlc/4vOed7d+/P3feeWepOhs2bCAtLc2z//XXX5Obm1tuDOUZNGgQQUFBhIeHe+ad3bZtGwkJCQQFBXHDDTcQHx/v81h3ZoSO7gNbjYH1ZVzmbXXmmM1zV+PqAaR6vX8n0EVEiocgNAXa4ySFC9RdZUtVvxKRxsBtwAqvKdXqUVpPnJXHUNUPRKSFiJSeyLe0pe4xW0SkeB5dgDX6/Ty5fYFwr+s3ceNqCiz0sYrZ7cBc97z7RGSfH3H4pcKEVkQ24EwNUdIvvXdUVUWkzCfMRORGYBGQqM70EL7qPIzz1wmtW7euKDRjjDHGXCTvh6UK874h+1+pPD/1P/nvZ6dQL5iAnXe22Pjx48uMoTzlzTtbEXfowVFVjRCRJMpemMDX3LTeBKd394KEWETu8nGuICBbL3EMrB/KivWsV1kQcKuqXrBUmoi8irOK2WARaYvT4/uDqnAMrar21e/nEvN+vQ0cdxPV4oT1hK9zuH8JrAV+qaoflXOtP6tqtKpGX3fddZd2R8YYY4wpk/c0Xd+mb6dRp3hCfv4G7ScuDOh5Z1NTU8uN4eqrr+abb765qDhiY2NZuXIlRUVFHD9+vMxVwdzz5otIXWBUOaccKCL1RaQFTtK7s8T764Gfu+dBRDq4q229B4wRkYZu+TWq+jVwWEQS3DIRkZ/6uObW4phEJA445R5bkeHuMT1VXLxEAAAGmUlEQVT5fh7dkopXMcOtW5xcNwWy3O0kr/pbgP9w63bGGXZQJSr7UNgaINHdTsSZDPgCInIVsApnTrW3Sr5vjDHGmOrzZfb3q6oWzzvrXR6o887Omzev3Bh+yHlnn332WYCf4Cwh+2mpCt/bh7OS10c4c71+WeL9+Tirde12HxT7E85Y1HU4OVeKO1fsL9z6o4AHRWQvcAAY6OOaM4Bu7sf7M/k+b6uIr3l0S5qIMzfuPhFJAx5xy8uab/ePQGMR+QR4Bmc8LgAiMl9Eov2MrZRKzUPr/oWxHGcg8BGcabu+cgN6RFXHichoYAFOQxdLUtXU0mf8ns1Da4wxxlS94iVhSwpp1oDtU39WAxFd3sqad7Yk73lofRGRGUCueq20ZapOpR4KU2cVi1KLGKszVcU4d3sxztQQxhhjjKlhT9zV8YIFB6D0NF3me1U976z5YVR2lgNjjDHGBJCSCw7c1KwBT9zV0efMBoYyx81eLFWdUSUnMj5ZQmuMMcZcYQZFhVgCa2qVyj4UZowxxhhjTI2yhNYYY4wxxgQ0S2iNMcYYY0xAs4TWGGOMMcYENEtojTHGGGNMQLOE1hhjjDHGBDRLaI0xxhhjTECzhNYYY4wxxgQ0UdWajsEnETkJHKnpOKrJtcCpmg7iCmLtXf2szauftXn1svaufpdbm7dR1etqOogr1WWb0F5JRCRFVaNrOo4rhbV39bM2r37W5tXL2rv6WZsbbzbkwBhjjDHGBDRLaI0xxhhjTECzhPby8OeaDuAKY+1d/azNq5+1efWy9q5+1ubGw8bQGmOMMcaYgGY9tMYYY4wxJqBZQlsDROQaEXlPRD53vzb3USdSRD4UkQMisk9EhtdErIFMRPqJSLqIHBSRqT7eryciy9z3/1dE2lZ/lLWLH20+WUTS3J/p90WkTU3EWVtU1N5e9YaKiIqIPRFeSf60uYjc7/6cHxCRv1V3jLWNH/+vtBaRjSKyx/2/5Z6aiNPULBtyUANE5HfAV6o60/3H2VxVnyxRpwOgqvq5iNwE7AJ+oqrZNRBywBGRYOAz4A7gC2AnMFJV07zqPAp0UdVHRGQEMFhV7Q+HS+Rnm8cD/6uq34rIz4E4a/NL4097u/WuBtYCVwHjVTWlumOtLfz8GW8PLAd+pqpnRORHqnqiRgKuBfxs8z8De1T1jyISDryjqm1rIl5Tc6yHtmYMBBa62wuBQSUrqOpnqvq5u/0lcAKwCZv91wM4qKqHVPU88CZOu3vz/j68BfQREanGGGubCttcVTeq6rfu7kdAy2qOsTbx52cc4FngReBcdQZXS/nT5g8Br6nqGQBLZivNnzZXoIm73RT4shrjM5cJS2hrxvWqeszd/jdwfXmVRaQHTu/Kv37owGqRECDTa/8Lt8xnHVUtAHKAFtUSXe3kT5t7exD4fz9oRLVbhe0tIl2BVqq6tjoDq8X8+RnvAHQQke0i8pGI9Ku26Gonf9p8BjBaRL4A3gEmVE9o5nJSp6YDqK1EZANwg4+3fum9o6oqImWO+xCRG4FFQKKqFlVtlMbUDBEZDUQDvWs6ltpKRIKAPwBJNRzKlaYO0B6Iw/kEYouIRNhwsR/USCBZVX8vIjHAIhHpbL8zryyW0P5AVLVvWe+JyHERuVFVj7kJq8+PpESkCc7Yt1+q6kc/UKi1VRbQymu/pVvmq84XIlIH56Oq09UTXq3kT5sjIn1x/rDrrarfVVNstVFF7X010BnY5I6kuQFYIyIDbBztJfPnZ/wLnHHi+cBhEfkMJ8HdWT0h1jr+tPmDQD8AVf1QROoD11LG71ZTO9mQg5qxBkh0txOBt0tWEJGrgFXAX1X1rWqMrbbYCbQXkVC3LUfgtLs37+/DMOADtackK6PCNheRKOBPwAAbW1hp5ba3quao6rWq2tZ9QOYjnHa3ZPbS+fP/ymqc3llE5FqcIQiHqjPIWsafNj8K9AEQkZ8A9YGT1RqlqXGW0NaMmcAdIvI50NfdR0SiRWS+W+d+4HYgSURS3VdkzYQbeNwxseOB9cAnwHJVPSAiz4jIALfa60ALETkITAbKnPbIVMzPNp8FNAZWuD/TJX8xGT/52d6mCvnZ5uuB0yKSBmwEnlBV++TnEvnZ5v8FPCQie4GlQJJ1Tlx5bNouY4wxxhgT0KyH1hhjjDHGBDRLaI0xxhhjTECzhNYYY4wxxgQ0S2iNMcYYY0xAs4TWGGOMMcYENEtojTHGGGNMQLOE1hhjjDHGBDRLaI0xxhhjTED7//NIh15yqXfYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced = reduce_to_k_dim(corpus_embeddings)\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(reduced)) :\n",
    "  embedding = reduced[i]\n",
    "  xs.append(embedding[0])\n",
    "  ys.append(embedding[1])\n",
    "  labels.append(corpus[i])\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "  plt.annotate(label, (xs[i], ys[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuwpmW-EirJR"
   },
   "source": [
    "We can see that sentences with the same meaning are almost on the same coordinates. Sentences with very similar meanings still form tight clusters (like the cluster formed by the sentences in the form \"A man is eating ***\"). We can also see that clusters with similar words or words which are seen frequently together are close, for example the clusters with sentences containing \"monkey, gorilla\", and \"cheetah\" are close. The clusters which begin with \"A man\" are also close in the same fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXqSyMyy-bm8"
   },
   "source": [
    "### Question 4.4: Independent Analysis of Bias in Word Vectors [code + written] (4 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZynvZnq-nqk"
   },
   "source": [
    "Select a corpus of interest, or examples of interest and shed light on one source of bias from SentenceBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "DQyOEVUWvEmI",
    "outputId": "17af3848-184a-4519-b4cb-3fbd506805eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 6 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = ['She is a nurse',\n",
    "          'He is a nurse',\n",
    "          'This person is a nurse',\n",
    "          'She is a plumber',\n",
    "          'He is a plumber',\n",
    "          'This person is a plumber',\n",
    "          \n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Normalize the embeddings to unit length\n",
    "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
    "reduced = reduce_to_k_dim(corpus_embeddings)\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(reduced)) :\n",
    "  embedding = reduced[i]\n",
    "  xs.append(embedding[0])\n",
    "  ys.append(embedding[1])\n",
    "  labels.append(corpus[i])\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "  plt.annotate(label, (xs[i], ys[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKC1hAZem5XA"
   },
   "source": [
    "In this examples, we replace \"This person\" by \"she\" or \"he\" to see if the model tends to relate an activity to the male or female gender. By doing this, we can see the model associates the activity of \"nurse\" to the female gender more than the male gender, and associates the activity of \"plumber\" to the male gender more than the female gender\". This show a bias that reflects the gender stereotype."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9WY9c6iwI0Lv",
    "KK7YbNCyJaqk",
    "5TRcD4MeHFnt",
    "qkDLV8yILNNS",
    "Mes_RnLNVXBX",
    "vJs_f30AYmKN",
    "edzctdyh0rDm"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
